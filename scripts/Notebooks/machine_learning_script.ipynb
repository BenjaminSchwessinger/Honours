{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../machine_learning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../machine_learning.py\n",
    "\n",
    "\"\"\"\n",
    "Script aims to read in the reference_dataframe file, select a taxonomic\n",
    "level and group, and read the path to the location of that data. It then\n",
    "prepares data for machine learning by converting base pair coding to numerical\n",
    "encoding, pads it out and then runs the algorithm\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "def max_seq_len(SeqIO_dict):\n",
    "    \"\"\"\n",
    "    Function takes a SeqIO_dict and returns the lengths of the\n",
    "    longest sequence\n",
    "    \"\"\"\n",
    "    total_lens = []\n",
    "    for key in SeqIO_dict.keys():\n",
    "        total_lens.append(len(SeqIO_dict[key].seq))\n",
    "    return max(total_lens)\n",
    "\n",
    "def numberfy(SeqIO_dict, seq_len, nsubsample):\n",
    "    \"\"\"\n",
    "    Take SeqIO_dict and return SeqIO_dict were bases have been replaced\n",
    "    with numbers\n",
    "    ACGT- replaced with 01234\n",
    "    Take the seq_len each sequence should have\n",
    "    \"\"\"\n",
    "    num_dict = {}\n",
    "    \n",
    "    keys = list(SeqIO_dict.keys())\n",
    "    randkeys = random.sample(keys, k=nsubsample)\n",
    "    \n",
    "    \n",
    "    for key in randkeys:\n",
    "        seq = str(SeqIO_dict[key].seq).replace(\"A\",'0 ')\\\n",
    "        .replace(\"C\",'1 ').replace(\"G\",'2 ').replace(\"T\",'3 ')\n",
    "        seq_new = seq + '4 '*(seq_len -int(len(seq)/2))\n",
    "        num_dict[key] = list(map(int, seq_new.split(' ')[:-1]))\n",
    "    return num_dict\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"\"\"\n",
    "Script aims to read in the reference_dataframe file, select a taxonomic\n",
    "level and group, and read the path to the location of that data. It then\n",
    "prepares data for machine learning by converting base pair coding to numerical\n",
    "encoding, pads it out and then runs the algorithm\n",
    "\"\"\")\n",
    "parser.add_argument(\"ref_df_fn\", help=\"File path to the reference dataframe\")\n",
    "parser.add_argument(\"data_root\", help=\"Root folder for analysis/\")\n",
    "parser.add_argument(\"--tax_rank\", \"-r\", help=\"taxonomic rank for analysis\")\n",
    "parser.add_argument(\"--name\", \"-n\", help=\"name of rank to select from\")\n",
    "parser.add_argument(\"--n_reads\", \"-c\", help=\"count of reads per class\")\n",
    "group = parser.add_mutually_exclusive_group()\n",
    "group.add_argument(\"--verbose\", \"-v\", \"--v\", action=\"store_true\")\n",
    "group.add_argument(\"--quiet\", \"-q\", \"--q\", action=\"store_true\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# assign required arguments to variables\n",
    "ref_df_fn = args.ref_df_fn\n",
    "data_root = args.data_root\n",
    "\n",
    "# assign a number of reads per class\n",
    "n_reads = int(args.n_reads)\n",
    "\n",
    "# test to make sure both required file paths are input\n",
    "try:\n",
    "    os.path.exists(ref_df_fn)\n",
    "except:\n",
    "    print('Cannot find %s' % ref_df_fn)\n",
    "try:\n",
    "    os.path.exists(data_root)\n",
    "except:\n",
    "    print('Cannot find %s' % data_root)\n",
    "    \n",
    "# assign flagged variables as lower case\n",
    "tax_rank = args.tax_rank.lower()\n",
    "name = args.name.lower()\n",
    "\n",
    "if args.verbose:\n",
    "    print('\\033[1;34m' + \"Reference dataframe is at \" + ref_df_fn + '\\033[0m')\n",
    "    print('\\033[1;34m' + \"Root directory is at \" + data_root + '\\033[0m')\n",
    "    print('\\033[1;34m' + \"Tax Rank is \" + tax_rank + '\\033[0m')\n",
    "    print('\\033[1;34m' + \"Name is \" + name + '\\033[0m')\n",
    "    print('\\033[1;34m' + \"Count of reads per sample is\", n_reads,'\\033[0m')\n",
    "\n",
    "# read in the reference dataframe from the argument path\n",
    "ref_df = pd.read_csv(ref_df_fn, index_col=None)\n",
    "\n",
    "# check whether the reference dataframe implies there are enough reads\n",
    "# to continue given n_reads\n",
    "try:\n",
    "    if ref_df[ref_df[\"# reads after length filtering\"] \\\n",
    "              < n_reads].shape[0] > 0 :\n",
    "        print(\"These species need more reads.\")\n",
    "        print(ref_df[ref_df[\"# reads after length filtering\"] \\\n",
    "              < n_reads])\n",
    "        #exit()\n",
    "except:\n",
    "    print('Check %s to have the wanted column names' % ref_df_fn)\n",
    "\n",
    "# assign the indices of the reference_dataframe as keys to a dictionary\n",
    "# where the values are that index's path's dataframe\n",
    "indices = ref_df[ref_df[tax_rank] == name].index\n",
    "SeqIO_dicts = {}\n",
    "for index in indices:\n",
    "    fasta_path = ref_df.loc[index, 'path to length filtering']\n",
    "    try:\n",
    "        SeqIO_dicts[index] = SeqIO.to_dict(SeqIO.parse(fasta_path, \"fasta\"))\n",
    "    except:\n",
    "        print('Check location of fasta files')\n",
    "        print(fasta_path, \"does not exist\")\n",
    "        \n",
    "# determine the maximum sequence length of accepted sequences\n",
    "total_lens = []\n",
    "for key, value in SeqIO_dicts.items():\n",
    "    total_lens.append(max_seq_len(value))\n",
    "print('\\033[0;32m'+\"The maximum sequence length of all sampled sequences is\"+ '\\033[1;37m',max(total_lens),'\\033[0m')\n",
    "\n",
    "# randomly subsample n_reads number of reads from each index's corresponding\n",
    "# set of reds, convert base pair coding to numerical coding and \n",
    "# pad to the max sequence length\n",
    "numSeqIO_dicts = {}\n",
    "max_len = max(total_lens)\n",
    "for key, value in SeqIO_dicts.items():\n",
    "    numSeqIO_dicts[key] = numberfy(value, max_len, n_reads)\n",
    "\n",
    "# append the numberfy'd sequences to a numpy array\n",
    "seq_list = []\n",
    "for index in indices:\n",
    "    seq_list.append(np.array(list(numSeqIO_dicts[index].values())))\n",
    "seq_comb = np.concatenate(seq_list, axis = 0)\n",
    "\n",
    "# determine the number of classes and generate an array of ids\n",
    "num_class = len(numSeqIO_dicts.keys())\n",
    "ids_comb = np.zeros( (n_reads*num_class,num_class) )\n",
    "for i in range(0, num_class):\n",
    "    ids_comb[i*n_reads:(i+1)*n_reads,i] = 1\n",
    "\n",
    "print(ids_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
