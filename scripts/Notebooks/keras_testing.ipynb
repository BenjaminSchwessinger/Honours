{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(20000, 3807)\n",
      "[2 0 0 ... 0 0 0]\n",
      "[3 1 0 ... 0 0 0]\n",
      "data_class_2.shape:  (10000, 3807)\n",
      "data_class_6.shape:  (10000, 3807)\n",
      "samples_per_class:  10000\n",
      "samples_count:  20000\n",
      "all_data.shape :  (20000, 3807)\n",
      "all_labels.shape :  (20000,)\n",
      "20000\n",
      "X_train.shape :  (17000, 3807)\n",
      "X_test.shape :  (2999, 3807)\n",
      "Y_train.shape :  (17000,)\n",
      "Y_test.shape :  (2999,)\n",
      "WARNING:tensorflow:From /home/tavish/anaconda3/envs/honours1/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/tavish/anaconda3/envs/honours1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 17000 samples, validate on 2999 samples\n",
      "Epoch 1/40\n",
      "17000/17000 [==============================] - 4s 243us/step - loss: 0.4526 - accuracy: 0.7969 - val_loss: 0.3401 - val_accuracy: 0.8750\n",
      "Epoch 2/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.2449 - accuracy: 0.9085 - val_loss: 0.2040 - val_accuracy: 0.9250\n",
      "Epoch 3/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.2089 - accuracy: 0.9215 - val_loss: 0.1929 - val_accuracy: 0.9260\n",
      "Epoch 4/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.1899 - accuracy: 0.9262 - val_loss: 0.1820 - val_accuracy: 0.9320\n",
      "Epoch 5/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.1689 - accuracy: 0.9368 - val_loss: 0.1679 - val_accuracy: 0.9410\n",
      "Epoch 6/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.1471 - accuracy: 0.9424 - val_loss: 0.1499 - val_accuracy: 0.9403\n",
      "Epoch 7/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.1318 - accuracy: 0.9478 - val_loss: 0.1530 - val_accuracy: 0.9373\n",
      "Epoch 8/40\n",
      "17000/17000 [==============================] - 3s 196us/step - loss: 0.1157 - accuracy: 0.9520 - val_loss: 0.1598 - val_accuracy: 0.9410\n",
      "Epoch 9/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.1073 - accuracy: 0.9554 - val_loss: 0.1441 - val_accuracy: 0.9493\n",
      "Epoch 10/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0943 - accuracy: 0.9631 - val_loss: 0.1738 - val_accuracy: 0.9463\n",
      "Epoch 11/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0899 - accuracy: 0.9668 - val_loss: 0.1637 - val_accuracy: 0.9500\n",
      "Epoch 12/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0809 - accuracy: 0.9702 - val_loss: 0.1527 - val_accuracy: 0.9513\n",
      "Epoch 13/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0739 - accuracy: 0.9723 - val_loss: 0.1433 - val_accuracy: 0.9513\n",
      "Epoch 14/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0667 - accuracy: 0.9774 - val_loss: 0.1512 - val_accuracy: 0.9520\n",
      "Epoch 15/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.0630 - accuracy: 0.9783 - val_loss: 0.1391 - val_accuracy: 0.9543\n",
      "Epoch 16/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0548 - accuracy: 0.9812 - val_loss: 0.1358 - val_accuracy: 0.9580\n",
      "Epoch 17/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0553 - accuracy: 0.9825 - val_loss: 0.1520 - val_accuracy: 0.9550\n",
      "Epoch 18/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0459 - accuracy: 0.9857 - val_loss: 0.1489 - val_accuracy: 0.9567\n",
      "Epoch 19/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.0527 - accuracy: 0.9830 - val_loss: 0.1596 - val_accuracy: 0.9570\n",
      "Epoch 20/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.0420 - accuracy: 0.9891 - val_loss: 0.1799 - val_accuracy: 0.9553\n",
      "Epoch 21/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0424 - accuracy: 0.9879 - val_loss: 0.1618 - val_accuracy: 0.9577\n",
      "Epoch 22/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.0376 - accuracy: 0.9889 - val_loss: 0.1673 - val_accuracy: 0.9583\n",
      "Epoch 23/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.0379 - accuracy: 0.9895 - val_loss: 0.1714 - val_accuracy: 0.9587\n",
      "Epoch 24/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0353 - accuracy: 0.9907 - val_loss: 0.1765 - val_accuracy: 0.9577\n",
      "Epoch 25/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0331 - accuracy: 0.9916 - val_loss: 0.1962 - val_accuracy: 0.9580\n",
      "Epoch 26/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0276 - accuracy: 0.9929 - val_loss: 0.1919 - val_accuracy: 0.9577\n",
      "Epoch 27/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.0261 - accuracy: 0.9931 - val_loss: 0.1998 - val_accuracy: 0.9587\n",
      "Epoch 28/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.0490 - accuracy: 0.9899 - val_loss: 0.1917 - val_accuracy: 0.9583\n",
      "Epoch 29/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.0357 - accuracy: 0.9915 - val_loss: 0.2462 - val_accuracy: 0.9500\n",
      "Epoch 30/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0260 - accuracy: 0.9941 - val_loss: 0.2121 - val_accuracy: 0.9607\n",
      "Epoch 31/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0377 - accuracy: 0.9920 - val_loss: 0.2102 - val_accuracy: 0.9597\n",
      "Epoch 32/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.0470 - accuracy: 0.9928 - val_loss: 0.2275 - val_accuracy: 0.9587\n",
      "Epoch 33/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.0256 - accuracy: 0.9948 - val_loss: 0.2336 - val_accuracy: 0.9573\n",
      "Epoch 34/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0319 - accuracy: 0.9934 - val_loss: 0.2317 - val_accuracy: 0.9593\n",
      "Epoch 35/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.0254 - accuracy: 0.9949 - val_loss: 0.2484 - val_accuracy: 0.9563\n",
      "Epoch 36/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.0376 - accuracy: 0.9932 - val_loss: 0.2590 - val_accuracy: 0.9553\n",
      "Epoch 37/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0251 - accuracy: 0.9950 - val_loss: 0.2576 - val_accuracy: 0.9570\n",
      "Epoch 38/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.2267 - val_accuracy: 0.9573\n",
      "Epoch 39/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.0459 - accuracy: 0.9919 - val_loss: 0.2397 - val_accuracy: 0.9593\n",
      "Epoch 40/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.0179 - accuracy: 0.9965 - val_loss: 0.2291 - val_accuracy: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f3044a59390>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z. tritici vs C. globuliformis\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_seqs.csv.npz')\n",
    "data = data_npz['arr_0']\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_ids.csv.npz')\n",
    "labels = labels_npz['arr_0']\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print(labels.shape)\n",
    "print(data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_2 = data[(labels == 2)]\n",
    "data_class_6 = data[(labels == 6)]\n",
    "# Print an entry to visualise this\n",
    "print(data_class_2[50])\n",
    "print(data_class_6[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_per_class = data_class_2.shape[0]\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = np.vstack((data_class_2, data_class_6))\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*all_data.shape[0])\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training ad test sets\n",
    "X_train = all_data[indices_train,:]\n",
    "Y_train = all_labels[indices_train]\n",
    "X_test = all_data[indices_test,:]\n",
    "Y_test = all_labels[indices_test]\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(20000, 3489)\n",
      "[1 2 0 ... 0 0 0]\n",
      "[3 1 1 ... 0 0 0]\n",
      "data_class_2.shape:  (10000, 3489)\n",
      "data_class_3.shape:  (10000, 3489)\n",
      "samples_per_class:  10000\n",
      "samples_count:  20000\n",
      "all_data.shape :  (20000, 3489)\n",
      "all_labels.shape :  (20000,)\n",
      "20000\n",
      "X_train.shape :  (17000, 3489)\n",
      "X_test.shape :  (2999, 3489)\n",
      "Y_train.shape :  (17000,)\n",
      "Y_test.shape :  (2999,)\n",
      "Train on 17000 samples, validate on 2999 samples\n",
      "Epoch 1/40\n",
      "17000/17000 [==============================] - 4s 210us/step - loss: 0.7341 - accuracy: 0.5252 - val_loss: 0.6597 - val_accuracy: 0.5542\n",
      "Epoch 2/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.6479 - accuracy: 0.6078 - val_loss: 0.6762 - val_accuracy: 0.5605\n",
      "Epoch 3/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.5608 - accuracy: 0.7022 - val_loss: 0.4414 - val_accuracy: 0.8476\n",
      "Epoch 4/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.4942 - accuracy: 0.7457 - val_loss: 0.7065 - val_accuracy: 0.5819\n",
      "Epoch 5/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.4466 - accuracy: 0.7866 - val_loss: 0.5016 - val_accuracy: 0.6949\n",
      "Epoch 6/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.4063 - accuracy: 0.8071 - val_loss: 0.6072 - val_accuracy: 0.6932\n",
      "Epoch 7/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.3676 - accuracy: 0.8369 - val_loss: 0.4460 - val_accuracy: 0.7492\n",
      "Epoch 8/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.3539 - accuracy: 0.8444 - val_loss: 0.2456 - val_accuracy: 0.9153\n",
      "Epoch 9/40\n",
      "17000/17000 [==============================] - 3s 196us/step - loss: 0.3279 - accuracy: 0.8607 - val_loss: 0.4216 - val_accuracy: 0.8076\n",
      "Epoch 10/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.3127 - accuracy: 0.8695 - val_loss: 0.2163 - val_accuracy: 0.9266\n",
      "Epoch 11/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.2860 - accuracy: 0.8835 - val_loss: 0.4467 - val_accuracy: 0.7953\n",
      "Epoch 12/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.2827 - accuracy: 0.8828 - val_loss: 0.2451 - val_accuracy: 0.8946\n",
      "Epoch 13/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.2624 - accuracy: 0.8925 - val_loss: 0.1923 - val_accuracy: 0.9333\n",
      "Epoch 14/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.2622 - accuracy: 0.8918 - val_loss: 0.2025 - val_accuracy: 0.9286\n",
      "Epoch 15/40\n",
      "17000/17000 [==============================] - 3s 195us/step - loss: 0.2486 - accuracy: 0.9013 - val_loss: 0.1952 - val_accuracy: 0.9260\n",
      "Epoch 16/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.2416 - accuracy: 0.9042 - val_loss: 0.2174 - val_accuracy: 0.9120\n",
      "Epoch 17/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.2295 - accuracy: 0.9099 - val_loss: 0.3273 - val_accuracy: 0.8556\n",
      "Epoch 18/40\n",
      "17000/17000 [==============================] - 3s 196us/step - loss: 0.2242 - accuracy: 0.9115 - val_loss: 0.4198 - val_accuracy: 0.8179\n",
      "Epoch 19/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.2117 - accuracy: 0.9162 - val_loss: 0.1738 - val_accuracy: 0.9363\n",
      "Epoch 20/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.2117 - accuracy: 0.9176 - val_loss: 0.2456 - val_accuracy: 0.8963\n",
      "Epoch 21/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.2008 - accuracy: 0.9191 - val_loss: 0.4048 - val_accuracy: 0.8346\n",
      "Epoch 22/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.2034 - accuracy: 0.9183 - val_loss: 0.7443 - val_accuracy: 0.7202\n",
      "Epoch 23/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.1980 - accuracy: 0.9205 - val_loss: 0.2647 - val_accuracy: 0.8896\n",
      "Epoch 24/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.1850 - accuracy: 0.9284 - val_loss: 0.1780 - val_accuracy: 0.9303\n",
      "Epoch 25/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.1897 - accuracy: 0.9263 - val_loss: 0.1648 - val_accuracy: 0.9380\n",
      "Epoch 26/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.1801 - accuracy: 0.9279 - val_loss: 0.5848 - val_accuracy: 0.7876\n",
      "Epoch 27/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.1780 - accuracy: 0.9301 - val_loss: 0.1747 - val_accuracy: 0.9360\n",
      "Epoch 28/40\n",
      "17000/17000 [==============================] - 3s 196us/step - loss: 0.1797 - accuracy: 0.9284 - val_loss: 0.1686 - val_accuracy: 0.9370\n",
      "Epoch 29/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.1750 - accuracy: 0.9341 - val_loss: 0.1811 - val_accuracy: 0.9303\n",
      "Epoch 30/40\n",
      "17000/17000 [==============================] - 3s 196us/step - loss: 0.1642 - accuracy: 0.9363 - val_loss: 0.1873 - val_accuracy: 0.9276\n",
      "Epoch 31/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.1702 - accuracy: 0.9329 - val_loss: 0.3020 - val_accuracy: 0.8793\n",
      "Epoch 32/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.1658 - accuracy: 0.9341 - val_loss: 0.3225 - val_accuracy: 0.8756\n",
      "Epoch 33/40\n",
      "17000/17000 [==============================] - 3s 196us/step - loss: 0.1536 - accuracy: 0.9389 - val_loss: 0.2212 - val_accuracy: 0.9173\n",
      "Epoch 34/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.1521 - accuracy: 0.9406 - val_loss: 0.2252 - val_accuracy: 0.9190\n",
      "Epoch 35/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.1580 - accuracy: 0.9376 - val_loss: 0.1713 - val_accuracy: 0.9350\n",
      "Epoch 36/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.1512 - accuracy: 0.9391 - val_loss: 0.1920 - val_accuracy: 0.9276\n",
      "Epoch 37/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.1540 - accuracy: 0.9388 - val_loss: 0.1701 - val_accuracy: 0.9340\n",
      "Epoch 38/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.1430 - accuracy: 0.9420 - val_loss: 0.1780 - val_accuracy: 0.9336\n",
      "Epoch 39/40\n",
      "17000/17000 [==============================] - 3s 195us/step - loss: 0.1399 - accuracy: 0.9455 - val_loss: 0.1922 - val_accuracy: 0.9290\n",
      "Epoch 40/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.1390 - accuracy: 0.9438 - val_loss: 0.2071 - val_accuracy: 0.9216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f30201168d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z. tritici vs P. tritici-repentis\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b3_seqs.csv.npz')\n",
    "data = data_npz['arr_0']\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b3_ids.csv.npz')\n",
    "labels = labels_npz['arr_0']\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print(labels.shape)\n",
    "print(data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_2 = data[(labels == 2)]\n",
    "data_class_3 = data[(labels == 3)]\n",
    "# Print an entry to visualise this\n",
    "print(data_class_2[50])\n",
    "print(data_class_3[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "print('data_class_3.shape: ', data_class_3.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_per_class = data_class_2.shape[0]\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = np.vstack((data_class_2, data_class_3))\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*all_data.shape[0])\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training ad test sets\n",
    "X_train = all_data[indices_train,:]\n",
    "Y_train = all_labels[indices_train]\n",
    "X_test = all_data[indices_test,:]\n",
    "Y_test = all_labels[indices_test]\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(20000, 3505)\n",
      "[1 3 2 ... 0 0 0]\n",
      "[2 1 0 ... 0 0 0]\n",
      "data_class_4.shape:  (10000, 3505)\n",
      "data_class_5.shape:  (10000, 3505)\n",
      "samples_per_class:  10000\n",
      "samples_count:  20000\n",
      "all_data.shape :  (20000, 3505)\n",
      "all_labels.shape :  (20000,)\n",
      "20000\n",
      "X_train.shape :  (17000, 3505)\n",
      "X_test.shape :  (2999, 3505)\n",
      "Y_train.shape :  (17000,)\n",
      "Y_test.shape :  (2999,)\n",
      "Train on 17000 samples, validate on 2999 samples\n",
      "Epoch 1/40\n",
      "17000/17000 [==============================] - 4s 219us/step - loss: 0.7750 - accuracy: 0.4955 - val_loss: 0.6954 - val_accuracy: 0.4838\n",
      "Epoch 2/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.6951 - accuracy: 0.4991 - val_loss: 0.6934 - val_accuracy: 0.4825\n",
      "Epoch 3/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.6932 - accuracy: 0.4921 - val_loss: 0.6934 - val_accuracy: 0.4828\n",
      "Epoch 4/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6938 - accuracy: 0.5019 - val_loss: 0.6936 - val_accuracy: 0.4992\n",
      "Epoch 5/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6961 - accuracy: 0.5083 - val_loss: 0.6932 - val_accuracy: 0.5158\n",
      "Epoch 6/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6929 - accuracy: 0.5094 - val_loss: 0.6923 - val_accuracy: 0.5272\n",
      "Epoch 7/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.6915 - accuracy: 0.5294 - val_loss: 0.6924 - val_accuracy: 0.5182\n",
      "Epoch 8/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6871 - accuracy: 0.5464 - val_loss: 0.6904 - val_accuracy: 0.5408\n",
      "Epoch 9/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6828 - accuracy: 0.5642 - val_loss: 0.6957 - val_accuracy: 0.5275\n",
      "Epoch 10/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6767 - accuracy: 0.5752 - val_loss: 0.6923 - val_accuracy: 0.5252\n",
      "Epoch 11/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6690 - accuracy: 0.5908 - val_loss: 0.7032 - val_accuracy: 0.5242\n",
      "Epoch 12/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6655 - accuracy: 0.5967 - val_loss: 0.6955 - val_accuracy: 0.5308\n",
      "Epoch 13/40\n",
      "17000/17000 [==============================] - 4s 214us/step - loss: 0.6616 - accuracy: 0.6016 - val_loss: 0.6970 - val_accuracy: 0.5278\n",
      "Epoch 14/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6585 - accuracy: 0.6107 - val_loss: 0.6976 - val_accuracy: 0.5272\n",
      "Epoch 15/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6542 - accuracy: 0.6153 - val_loss: 0.7815 - val_accuracy: 0.5032\n",
      "Epoch 16/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6448 - accuracy: 0.6292 - val_loss: 0.7514 - val_accuracy: 0.5108\n",
      "Epoch 17/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.6432 - accuracy: 0.6296 - val_loss: 0.7754 - val_accuracy: 0.5292\n",
      "Epoch 18/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.6375 - accuracy: 0.6313 - val_loss: 0.7703 - val_accuracy: 0.5112\n",
      "Epoch 19/40\n",
      "17000/17000 [==============================] - 4s 214us/step - loss: 0.6353 - accuracy: 0.6354 - val_loss: 0.7229 - val_accuracy: 0.5365\n",
      "Epoch 20/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6276 - accuracy: 0.6411 - val_loss: 0.7454 - val_accuracy: 0.5388\n",
      "Epoch 21/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6233 - accuracy: 0.6495 - val_loss: 0.7070 - val_accuracy: 0.5305\n",
      "Epoch 22/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6192 - accuracy: 0.6556 - val_loss: 0.7252 - val_accuracy: 0.5372\n",
      "Epoch 23/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6159 - accuracy: 0.6545 - val_loss: 0.7821 - val_accuracy: 0.5105\n",
      "Epoch 24/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6137 - accuracy: 0.6534 - val_loss: 0.7581 - val_accuracy: 0.5332\n",
      "Epoch 25/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.6110 - accuracy: 0.6586 - val_loss: 0.7876 - val_accuracy: 0.5348\n",
      "Epoch 26/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.6054 - accuracy: 0.6605 - val_loss: 0.8077 - val_accuracy: 0.5268\n",
      "Epoch 27/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.5962 - accuracy: 0.6677 - val_loss: 0.8769 - val_accuracy: 0.5328\n",
      "Epoch 28/40\n",
      "17000/17000 [==============================] - 4s 208us/step - loss: 0.5998 - accuracy: 0.6684 - val_loss: 1.0086 - val_accuracy: 0.5028\n",
      "Epoch 29/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.5963 - accuracy: 0.6721 - val_loss: 0.8876 - val_accuracy: 0.5115\n",
      "Epoch 30/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.5898 - accuracy: 0.6728 - val_loss: 1.0477 - val_accuracy: 0.5102\n",
      "Epoch 31/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.5862 - accuracy: 0.6764 - val_loss: 0.7689 - val_accuracy: 0.5415\n",
      "Epoch 32/40\n",
      "17000/17000 [==============================] - 4s 214us/step - loss: 0.5796 - accuracy: 0.6812 - val_loss: 0.7630 - val_accuracy: 0.5415\n",
      "Epoch 33/40\n",
      "17000/17000 [==============================] - 4s 213us/step - loss: 0.5764 - accuracy: 0.6849 - val_loss: 0.7672 - val_accuracy: 0.5398\n",
      "Epoch 34/40\n",
      "17000/17000 [==============================] - 4s 209us/step - loss: 0.5813 - accuracy: 0.6809 - val_loss: 0.7319 - val_accuracy: 0.5402\n",
      "Epoch 35/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.5724 - accuracy: 0.6933 - val_loss: 0.7591 - val_accuracy: 0.5482\n",
      "Epoch 36/40\n",
      "17000/17000 [==============================] - 4s 214us/step - loss: 0.5690 - accuracy: 0.6908 - val_loss: 0.7675 - val_accuracy: 0.5318\n",
      "Epoch 37/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.5669 - accuracy: 0.6917 - val_loss: 0.7992 - val_accuracy: 0.5422\n",
      "Epoch 38/40\n",
      "17000/17000 [==============================] - 4s 212us/step - loss: 0.5670 - accuracy: 0.6917 - val_loss: 0.8802 - val_accuracy: 0.5408\n",
      "Epoch 39/40\n",
      "17000/17000 [==============================] - 4s 211us/step - loss: 0.5569 - accuracy: 0.6962 - val_loss: 0.8122 - val_accuracy: 0.5458\n",
      "Epoch 40/40\n",
      "17000/17000 [==============================] - 4s 214us/step - loss: 0.5517 - accuracy: 0.7049 - val_loss: 0.8340 - val_accuracy: 0.5282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f302010a320>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C. metapsilosis vs C. orthopsilosis\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_seqs.csv.npz')\n",
    "data = data_npz['arr_0']\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_ids.csv.npz')\n",
    "labels = labels_npz['arr_0']\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print(labels.shape)\n",
    "print(data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_4 = data[(labels == 4)]\n",
    "data_class_5 = data[(labels == 5)]\n",
    "# Print an entry to visualise this\n",
    "print(data_class_4[50])\n",
    "print(data_class_5[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_4.shape: ', data_class_4.shape)\n",
    "print('data_class_5.shape: ', data_class_5.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_per_class = data_class_4.shape[0]\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = np.vstack((data_class_4, data_class_5))\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*all_data.shape[0])\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training ad test sets\n",
    "X_train = all_data[indices_train,:]\n",
    "Y_train = all_labels[indices_train]\n",
    "X_test = all_data[indices_test,:]\n",
    "Y_test = all_labels[indices_test]\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(20000, 4352)\n",
      "[0 1 0 ... 0 0 0]\n",
      "[1 1 0 ... 0 0 0]\n",
      "data_class_4.shape:  (10000, 4352)\n",
      "data_class_3.shape:  (10000, 4352)\n",
      "samples_per_class:  10000\n",
      "samples_count:  20000\n",
      "all_data.shape :  (20000, 4352)\n",
      "all_labels.shape :  (20000,)\n",
      "20000\n",
      "X_train.shape :  (17000, 4352)\n",
      "X_test.shape :  (2999, 4352)\n",
      "Y_train.shape :  (17000,)\n",
      "Y_test.shape :  (2999,)\n",
      "Train on 17000 samples, validate on 2999 samples\n",
      "Epoch 1/40\n",
      "17000/17000 [==============================] - 4s 215us/step - loss: 0.7307 - accuracy: 0.5542 - val_loss: 0.6802 - val_accuracy: 0.5288\n",
      "Epoch 2/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.6645 - accuracy: 0.5955 - val_loss: 0.6099 - val_accuracy: 0.6689\n",
      "Epoch 3/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.6161 - accuracy: 0.6513 - val_loss: 0.5763 - val_accuracy: 0.6962\n",
      "Epoch 4/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.5772 - accuracy: 0.6889 - val_loss: 0.6842 - val_accuracy: 0.5682\n",
      "Epoch 5/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.5478 - accuracy: 0.7209 - val_loss: 0.5893 - val_accuracy: 0.6639\n",
      "Epoch 6/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.5225 - accuracy: 0.7348 - val_loss: 0.5307 - val_accuracy: 0.7302\n",
      "Epoch 7/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.5050 - accuracy: 0.7455 - val_loss: 0.4996 - val_accuracy: 0.7472\n",
      "Epoch 8/40\n",
      "17000/17000 [==============================] - 3s 203us/step - loss: 0.4882 - accuracy: 0.7588 - val_loss: 0.4712 - val_accuracy: 0.7706\n",
      "Epoch 9/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.4676 - accuracy: 0.7729 - val_loss: 0.6158 - val_accuracy: 0.6702\n",
      "Epoch 10/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.4501 - accuracy: 0.7833 - val_loss: 0.4576 - val_accuracy: 0.7739\n",
      "Epoch 11/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.4322 - accuracy: 0.7983 - val_loss: 0.5095 - val_accuracy: 0.7503\n",
      "Epoch 12/40\n",
      "17000/17000 [==============================] - 3s 206us/step - loss: 0.4373 - accuracy: 0.7962 - val_loss: 0.4653 - val_accuracy: 0.7756\n",
      "Epoch 13/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.4113 - accuracy: 0.8072 - val_loss: 0.4861 - val_accuracy: 0.7569\n",
      "Epoch 14/40\n",
      "17000/17000 [==============================] - 4s 206us/step - loss: 0.4119 - accuracy: 0.8059 - val_loss: 0.6463 - val_accuracy: 0.6532\n",
      "Epoch 15/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.3880 - accuracy: 0.8189 - val_loss: 0.4625 - val_accuracy: 0.7853\n",
      "Epoch 16/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.3818 - accuracy: 0.8245 - val_loss: 0.4949 - val_accuracy: 0.7653\n",
      "Epoch 17/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.3818 - accuracy: 0.8212 - val_loss: 0.4946 - val_accuracy: 0.7846\n",
      "Epoch 18/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.3652 - accuracy: 0.8319 - val_loss: 0.6420 - val_accuracy: 0.6959\n",
      "Epoch 19/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.3542 - accuracy: 0.8378 - val_loss: 0.4590 - val_accuracy: 0.7999\n",
      "Epoch 20/40\n",
      "17000/17000 [==============================] - 4s 206us/step - loss: 0.3499 - accuracy: 0.8379 - val_loss: 0.4982 - val_accuracy: 0.7789\n",
      "Epoch 21/40\n",
      "17000/17000 [==============================] - 4s 207us/step - loss: 0.3357 - accuracy: 0.8506 - val_loss: 0.5357 - val_accuracy: 0.7679\n",
      "Epoch 22/40\n",
      "17000/17000 [==============================] - 4s 207us/step - loss: 0.3321 - accuracy: 0.8518 - val_loss: 0.4874 - val_accuracy: 0.7973\n",
      "Epoch 23/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.3184 - accuracy: 0.8562 - val_loss: 0.4543 - val_accuracy: 0.8033\n",
      "Epoch 24/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.3124 - accuracy: 0.8639 - val_loss: 0.4632 - val_accuracy: 0.8119\n",
      "Epoch 25/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.3137 - accuracy: 0.8636 - val_loss: 0.4678 - val_accuracy: 0.8046\n",
      "Epoch 26/40\n",
      "17000/17000 [==============================] - 4s 206us/step - loss: 0.2951 - accuracy: 0.8702 - val_loss: 0.4830 - val_accuracy: 0.8079\n",
      "Epoch 27/40\n",
      "17000/17000 [==============================] - 4s 206us/step - loss: 0.2868 - accuracy: 0.8747 - val_loss: 0.5124 - val_accuracy: 0.7913\n",
      "Epoch 28/40\n",
      "17000/17000 [==============================] - 3s 206us/step - loss: 0.2870 - accuracy: 0.8759 - val_loss: 0.5217 - val_accuracy: 0.8043\n",
      "Epoch 29/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.2836 - accuracy: 0.8776 - val_loss: 0.5756 - val_accuracy: 0.7843\n",
      "Epoch 30/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.2694 - accuracy: 0.8894 - val_loss: 0.5051 - val_accuracy: 0.8063\n",
      "Epoch 31/40\n",
      "17000/17000 [==============================] - 4s 207us/step - loss: 0.2610 - accuracy: 0.8911 - val_loss: 0.5016 - val_accuracy: 0.8126\n",
      "Epoch 32/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.2540 - accuracy: 0.8956 - val_loss: 0.5031 - val_accuracy: 0.8183\n",
      "Epoch 33/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.2614 - accuracy: 0.8905 - val_loss: 0.6343 - val_accuracy: 0.7809\n",
      "Epoch 34/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.2479 - accuracy: 0.8987 - val_loss: 0.5047 - val_accuracy: 0.8233\n",
      "Epoch 35/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.2348 - accuracy: 0.9062 - val_loss: 0.9534 - val_accuracy: 0.6389\n",
      "Epoch 36/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.2267 - accuracy: 0.9071 - val_loss: 0.5224 - val_accuracy: 0.8189\n",
      "Epoch 37/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.2179 - accuracy: 0.9119 - val_loss: 0.5660 - val_accuracy: 0.8023\n",
      "Epoch 38/40\n",
      "17000/17000 [==============================] - 3s 205us/step - loss: 0.2237 - accuracy: 0.9134 - val_loss: 0.5951 - val_accuracy: 0.8103\n",
      "Epoch 39/40\n",
      "17000/17000 [==============================] - 3s 203us/step - loss: 0.2195 - accuracy: 0.9149 - val_loss: 0.7682 - val_accuracy: 0.7122\n",
      "Epoch 40/40\n",
      "17000/17000 [==============================] - 3s 203us/step - loss: 0.2068 - accuracy: 0.9174 - val_loss: 0.5924 - val_accuracy: 0.8066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f309a8190b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C. albicans vs C. metapsilosis\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4_seqs.csv.npz')\n",
    "data = data_npz['arr_0']\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4_ids.csv.npz')\n",
    "labels = labels_npz['arr_0']\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print(labels.shape)\n",
    "print(data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_4 = data[(labels == 4)]\n",
    "data_class_3 = data[(labels == 3)]\n",
    "# Print an entry to visualise this\n",
    "print(data_class_4[50])\n",
    "print(data_class_3[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_4.shape: ', data_class_4.shape)\n",
    "print('data_class_3.shape: ', data_class_3.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_per_class = data_class_4.shape[0]\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = np.vstack((data_class_4, data_class_3))\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*all_data.shape[0])\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training ad test sets\n",
    "X_train = all_data[indices_train,:]\n",
    "Y_train = all_labels[indices_train]\n",
    "X_test = all_data[indices_test,:]\n",
    "Y_test = all_labels[indices_test]\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000,)\n",
      "(20000, 3428)\n",
      "[0 3 3 ... 0 0 0]\n",
      "[0 0 1 ... 0 0 0]\n",
      "data_class_7.shape:  (10000, 3428)\n",
      "data_class_8.shape:  (10000, 3428)\n",
      "samples_per_class:  10000\n",
      "samples_count:  20000\n",
      "all_data.shape :  (20000, 3428)\n",
      "all_labels.shape :  (20000,)\n",
      "20000\n",
      "X_train.shape :  (17000, 3428)\n",
      "X_test.shape :  (2999, 3428)\n",
      "Y_train.shape :  (17000,)\n",
      "Y_test.shape :  (2999,)\n",
      "Train on 17000 samples, validate on 2999 samples\n",
      "Epoch 1/40\n",
      "17000/17000 [==============================] - 4s 208us/step - loss: 0.8008 - accuracy: 0.5122 - val_loss: 0.6819 - val_accuracy: 0.5765\n",
      "Epoch 2/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.6774 - accuracy: 0.5728 - val_loss: 0.6630 - val_accuracy: 0.5709\n",
      "Epoch 3/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.6480 - accuracy: 0.6299 - val_loss: 0.6868 - val_accuracy: 0.5525\n",
      "Epoch 4/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.6285 - accuracy: 0.6527 - val_loss: 0.5916 - val_accuracy: 0.7109\n",
      "Epoch 5/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.6053 - accuracy: 0.6740 - val_loss: 0.5853 - val_accuracy: 0.6929\n",
      "Epoch 6/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.5883 - accuracy: 0.6908 - val_loss: 0.5932 - val_accuracy: 0.6729\n",
      "Epoch 7/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.5718 - accuracy: 0.7025 - val_loss: 0.6965 - val_accuracy: 0.5415\n",
      "Epoch 8/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.5489 - accuracy: 0.7192 - val_loss: 0.7916 - val_accuracy: 0.5178\n",
      "Epoch 9/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.5415 - accuracy: 0.7338 - val_loss: 0.7542 - val_accuracy: 0.5348\n",
      "Epoch 10/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.5221 - accuracy: 0.7379 - val_loss: 0.5145 - val_accuracy: 0.7516\n",
      "Epoch 11/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.5162 - accuracy: 0.7439 - val_loss: 0.5009 - val_accuracy: 0.7693\n",
      "Epoch 12/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.4961 - accuracy: 0.7578 - val_loss: 0.6888 - val_accuracy: 0.6639\n",
      "Epoch 13/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.4897 - accuracy: 0.7631 - val_loss: 0.6547 - val_accuracy: 0.6032\n",
      "Epoch 14/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.4826 - accuracy: 0.7675 - val_loss: 0.4760 - val_accuracy: 0.7833\n",
      "Epoch 15/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.4683 - accuracy: 0.7752 - val_loss: 0.4719 - val_accuracy: 0.7826\n",
      "Epoch 16/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.4683 - accuracy: 0.7747 - val_loss: 0.6601 - val_accuracy: 0.6152\n",
      "Epoch 17/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.4562 - accuracy: 0.7825 - val_loss: 0.5963 - val_accuracy: 0.7196\n",
      "Epoch 18/40\n",
      "17000/17000 [==============================] - 3s 203us/step - loss: 0.4553 - accuracy: 0.7800 - val_loss: 0.4805 - val_accuracy: 0.7773\n",
      "Epoch 19/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.4382 - accuracy: 0.7977 - val_loss: 0.4584 - val_accuracy: 0.7923\n",
      "Epoch 20/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.4298 - accuracy: 0.7984 - val_loss: 0.5936 - val_accuracy: 0.7129\n",
      "Epoch 21/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.4261 - accuracy: 0.7974 - val_loss: 0.9025 - val_accuracy: 0.5635\n",
      "Epoch 22/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.4249 - accuracy: 0.8059 - val_loss: 0.4582 - val_accuracy: 0.7866\n",
      "Epoch 23/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.4094 - accuracy: 0.8140 - val_loss: 0.6270 - val_accuracy: 0.7069\n",
      "Epoch 24/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.4065 - accuracy: 0.8124 - val_loss: 0.9687 - val_accuracy: 0.5572\n",
      "Epoch 25/40\n",
      "17000/17000 [==============================] - 3s 201us/step - loss: 0.4080 - accuracy: 0.8137 - val_loss: 0.6729 - val_accuracy: 0.6472\n",
      "Epoch 26/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.3951 - accuracy: 0.8260 - val_loss: 0.7437 - val_accuracy: 0.6399\n",
      "Epoch 27/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.3876 - accuracy: 0.8246 - val_loss: 0.7391 - val_accuracy: 0.6385\n",
      "Epoch 28/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.3911 - accuracy: 0.8217 - val_loss: 0.5313 - val_accuracy: 0.7436\n",
      "Epoch 29/40\n",
      "17000/17000 [==============================] - 3s 198us/step - loss: 0.3806 - accuracy: 0.8254 - val_loss: 0.4700 - val_accuracy: 0.7753\n",
      "Epoch 30/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.3699 - accuracy: 0.8360 - val_loss: 0.4794 - val_accuracy: 0.7916\n",
      "Epoch 31/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.3722 - accuracy: 0.8342 - val_loss: 0.4287 - val_accuracy: 0.8069\n",
      "Epoch 32/40\n",
      "17000/17000 [==============================] - 3s 197us/step - loss: 0.3652 - accuracy: 0.8361 - val_loss: 0.4310 - val_accuracy: 0.8063\n",
      "Epoch 33/40\n",
      "17000/17000 [==============================] - 3s 199us/step - loss: 0.3511 - accuracy: 0.8485 - val_loss: 0.5263 - val_accuracy: 0.7516\n",
      "Epoch 34/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.3534 - accuracy: 0.8399 - val_loss: 0.4353 - val_accuracy: 0.8113\n",
      "Epoch 35/40\n",
      "17000/17000 [==============================] - 3s 204us/step - loss: 0.3500 - accuracy: 0.8435 - val_loss: 0.4330 - val_accuracy: 0.8079\n",
      "Epoch 36/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.3404 - accuracy: 0.8543 - val_loss: 0.4754 - val_accuracy: 0.7959\n",
      "Epoch 37/40\n",
      "17000/17000 [==============================] - 3s 203us/step - loss: 0.3339 - accuracy: 0.8479 - val_loss: 0.9576 - val_accuracy: 0.6019\n",
      "Epoch 38/40\n",
      "17000/17000 [==============================] - 3s 200us/step - loss: 0.3260 - accuracy: 0.8571 - val_loss: 0.4892 - val_accuracy: 0.7813\n",
      "Epoch 39/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.3230 - accuracy: 0.8579 - val_loss: 0.4525 - val_accuracy: 0.8136\n",
      "Epoch 40/40\n",
      "17000/17000 [==============================] - 3s 202us/step - loss: 0.3174 - accuracy: 0.8629 - val_loss: 0.4378 - val_accuracy: 0.8199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f30a0f54198>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y. mexicana vs Y. scolyti\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171207_FAH18654_b7+b8_seqs.csv.npz')\n",
    "data = data_npz['arr_0']\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171207_FAH18654_b7+b8_ids.csv.npz')\n",
    "labels = labels_npz['arr_0']\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print(labels.shape)\n",
    "print(data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_7 = data[(labels == 7)]\n",
    "data_class_8 = data[(labels == 8)]\n",
    "# Print an entry to visualise this\n",
    "print(data_class_7[50])\n",
    "print(data_class_8[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_7.shape: ', data_class_7.shape)\n",
    "print('data_class_8.shape: ', data_class_8.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_per_class = data_class_7.shape[0]\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = np.vstack((data_class_7, data_class_8))\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*all_data.shape[0])\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training ad test sets\n",
    "X_train = all_data[indices_train,:]\n",
    "Y_train = all_labels[indices_train]\n",
    "X_test = all_data[indices_test,:]\n",
    "Y_test = all_labels[indices_test]\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the keras model\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=40, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
