{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../summary_statistics.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../summary_statistics.py\n",
    "\n",
    "\"\"\"\n",
    "The goal of this program is to examine the distribution of reads within\n",
    "each file, and for the files generated after homology analysis.\n",
    "The program will generate summary statistics for the result of the homology\n",
    "analysis and save figures illustrating the read distribution for the\n",
    "frDNA reads\n",
    "\"\"\"\n",
    "\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord as SR\n",
    "from Bio.Blast import NCBIXML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "\n",
    "WHITE='\\033[1;37m'\n",
    "BLUE='\\033[0;34m'\n",
    "RED='\\033[0;31m'\n",
    "NC='\\033[0m'\n",
    "GREEN='\\033[0;32m'\n",
    "PURPLE='\\033[1;35m'\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"\"\"\n",
    "The goal of this program is to examine the distribution of reads within\n",
    "each file, and for the files generated after homology analysis.\n",
    "The program will generate summary statistics for the result of the homology\n",
    "analysis and save figures illustrating the read distribution for the\n",
    "frDNA reads\n",
    "\"\"\")\n",
    "group = parser.add_mutually_exclusive_group()\n",
    "group.add_argument(\"--verbose\", \"-v\", \"--v\", action=\"store_true\")\n",
    "group.add_argument(\"--quiet\", \"-q\", \"--q\", action=\"store_true\")\n",
    "parser.add_argument(\"full_file\", help=\"The full, unfiltered file containing all reads for this barcode\")\n",
    "parser.add_argument(\"input_folder\", help=\"The destination folder within which the .paf files are generated\")\n",
    "parser.add_argument(\"output_folder\", help=\"The destination folder for any outputs from this script - including summary statistics file and plots\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('\\033[0;35m'+'START'+'\\033[1;37m')\n",
    "\n",
    "output_folder = args.output_folder.rsplit('/', 1)[-2]\n",
    "input_folder = args.input_folder.rsplit('/', 1)[-2]\n",
    "if args.verbose:\n",
    "    print('\\033[0;31m' + \"Input folder is \" + input_folder + '\\033[1;37m')\n",
    "    print('\\033[0;31m' + \"Output folder is \" + output_folder + '\\033[1;37m')\n",
    "    print('\\033[0;34m' + \"Loading \" + args.full_file + '\\033[1;37m')\n",
    "\n",
    "# Load the full file containing all reads for this barcode\n",
    "full_file_dict = SeqIO.to_dict(SeqIO.parse(args.full_file, \"fastq\"))\n",
    "\n",
    "if args.verbose:\n",
    "    print('\\033[0;34m' + \"Loaded \" + args.full_file + '\\033[1;37m')\n",
    "\n",
    "# Extract the information about the lengths of the sequence for each read in this barcode\n",
    "full_lengths = []\n",
    "for key in full_file_dict:\n",
    "    full_lengths.append(len(full_file_dict[key].seq))\n",
    "full_lengths_len = len(full_file_dict)\n",
    "\n",
    "\n",
    "# Plot the spread of read lengths for this barcode\n",
    "    # Expect to see two peaks - one for EF1a and one for frDNA\n",
    "ax = sns.distplot(full_lengths, color=\"k\", kde=False, bins=5000)\n",
    "ax.set(xlim=(250, 3500))\n",
    "ax.set_title(\"Read spread for %s\" % '/'.join(args.full_file.rsplit('/')[-3:-1]), fontsize=15)\n",
    "ax.set_xlabel(\"Length of read\", fontsize=13)\n",
    "ax.set_ylabel(\"Number of reads\", fontsize=13)\n",
    "figure1 = ax.get_figure()\n",
    "# Save this figure out\n",
    "figure1.savefig('/'.join([output_folder, 'full_read_spread.png']))\n",
    "figure1.clf()\n",
    "if args.verbose:\n",
    "    print('\\033[0;32m' + \"Full spread image file saved to \" + '/'.join([output_folder, 'full_read_spread.png']) + '\\033[1;37m')\n",
    "    print('\\033[0;34m' + \"Loading \" + input_folder+\"/combined_test.paf\" + '\\033[1;37m')\n",
    "\n",
    "# Import the PAF file resulting from the minimap2 homology filtering\n",
    "full_paf = pd.read_csv(input_folder+\"/combined_test.paf\", sep='\\t', header=None, engine='python')\n",
    "if args.verbose:\n",
    "    print('\\033[0;34m' + \"Loaded \" + input_folder+\"/combined_test.paf\" + '\\033[1;37m')\n",
    "# Determine all the read ids present within the homology-filtered dataset\n",
    "# Then, create a dictionary extracting all the information from the full read file, but ONLY for reads present within the homology-filtered data\n",
    "full_dict = {}\n",
    "for key in full_paf[0].unique():\n",
    "    full_dict[key] = full_file_dict[key]\n",
    "\n",
    "# For each key in the homology-filtered dictionary, extract the sequence length and key\n",
    "full_paf_lengths = []\n",
    "full_keys = []\n",
    "for key in full_dict:\n",
    "    full_paf_lengths.append(len(full_dict[key].seq))\n",
    "    full_keys.append(key)\n",
    "\n",
    "mean = np.mean(full_paf_lengths)\n",
    "std = np.std(full_paf_lengths)\n",
    "\n",
    "if args.verbose:\n",
    "    print('\\033[1;33m' + 'Mean read length is %s' % mean + '\\033[1;37m')\n",
    "    print('\\033[1;33m' + 'Standard deviation of read length is %s' % std + '\\033[1;37m')\n",
    "    \n",
    "    \n",
    "length_filt_dict = full_dict.copy()\n",
    "for key in full_keys:\n",
    "    if len(full_dict[key].seq) < (mean-1.645*std) or len(full_dict[key].seq) > (mean+1.645*std):\n",
    "        del length_filt_dict[key]\n",
    "\n",
    "        \n",
    "        \n",
    "SeqIO.write(length_filt_dict.values(), '/'.join([output_folder, 'length_restricted_reads.fasta']), \"fasta\")\n",
    "if args.verbose:\n",
    "    print('\\033[1;36m' + 'Saved %s' % ('/'.join([output_folder, 'length_restricted_reads.fasta'])) + '\\033[1;37m')     \n",
    "    \n",
    "    \n",
    "    \n",
    "length_filt_lens = []\n",
    "len_filt_keys = []\n",
    "for key in length_filt_dict:\n",
    "    length_filt_lens.append(len(length_filt_dict[key].seq))\n",
    "    len_filt_keys.append(key)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "# Extract the qscores\n",
    "# if args.verbose:\n",
    "#     print('\\033[0;34m' + \"Loading \" + 'Basecalled/'+'/'.join(args.full_file.rsplit('/')[-3:-1])+'/sequencing_summary.txt' + '\\033[1;37m')\n",
    "# summ_stats_csv = pd.read_csv('Basecalled/'+'/'.join(args.full_file.rsplit('/')[-3:-1])+'/sequencing_summary.txt', sep='\\t', header=None, names=['filename', 'read_id', 'run_id', 'batch_id', 'channel', 'mux', 'start_time', 'duration', 'num_events', 'passes_filtering', 'template_start', 'num_events_template', 'template_duration', 'sequence_length_template', 'mean_qscore_template', 'strand_score_template', 'median_template', 'mad_template'], engine='python')\n",
    "# summ_stats_csv = pd.DataFrame(summ_stats_csv[1:])\n",
    "# summary_list = []\n",
    "# for column, row in summ_stats_csv.iterrows():\n",
    "#     if row['read_id'] in full_keys:\n",
    "#         summary_list.append([row['read_id'], row['mean_qscore_template']])\n",
    "# summary_frame = pd.DataFrame(summary_list)\n",
    "# if args.verbose:\n",
    "#     print('\\033[0;34m' + \"Finished with \" + 'Basecalled/'+'/'.join(args.full_file.rsplit('/')[-3:-1])+'/sequencing_summary.txt' + '\\033[1;37m')\n",
    "    \n",
    "# Create a dictionary containing the statistics for the filtered dataset\n",
    "    # Total no. frDNA reads, Min. read length, Max. read length, Mean read length, Median read length, Quality score\n",
    "\n",
    "stats_dict = {'number of frDNA reads':len(length_filt_lens),'minimum read length':min(length_filt_lens),'maximum read length':max(length_filt_lens),'mean read length':\"{:.0f}\".format(np.mean(length_filt_lens)),'median read length':\"{:.0f}\".format(np.median(length_filt_lens))\n",
    "#               ,'min_qscore':\"{:.2f}\".format(min(summary_frame[1].astype(float))), 'max_qscore':\"{:.2f}\".format(max(summary_frame[1].astype(float))), 'mean_qscore':\"{:.2f}\".format(np.mean(summary_frame[1].astype(float))), 'median_qscore':\"{:.2f}\".format(np.median(summary_frame[1].astype(float)))\n",
    "             }\n",
    "stats = pd.DataFrame(stats_dict, index=['%s' % '/'.join(args.full_file.rsplit('/')[-3:-1])])    \n",
    "              \n",
    "bx = sns.distplot(length_filt_lens, color=\"k\", kde=False)\n",
    "bx.set(xlim=(250, 3500))\n",
    "bx.set_title(\"frDNA reads for %s\" % '/'.join(args.full_file.rsplit('/')[-3:-1]), fontsize=15)\n",
    "bx.set_xlabel(\"Length of read\", fontsize=13)\n",
    "bx.set_ylabel(\"Number of reads\", fontsize=13)\n",
    "figure2 = bx.get_figure()\n",
    "figure2.savefig('/'.join([output_folder, 'frDNA_len_filt_full.png']))\n",
    "figure2.clf()\n",
    "if args.verbose:\n",
    "    print('\\033[0;32m' + \"frDNA spread image file saved to \" + '/'.join([output_folder, 'frDNA_len_filt_full.png']) + '\\033[1;37m')\n",
    "\n",
    "cx = sns.distplot(length_filt_lens, color=\"k\", kde=False)\n",
    "cx.set(xlim=((mean-1.645*std)-100, (mean+1.645*std)+100))\n",
    "cx.set_title(\"frDNA reads for %s\" % '/'.join(args.full_file.rsplit('/')[-3:-1]), fontsize=15)\n",
    "cx.set_xlabel(\"Length of read\", fontsize=13)\n",
    "cx.set_ylabel(\"Number of reads\", fontsize=13)\n",
    "figure3 = cx.get_figure()\n",
    "figure3.savefig('/'.join([output_folder, 'frDNA_len_filt_limited.png']))\n",
    "figure3.clf()\n",
    "if args.verbose:\n",
    "    print('\\033[0;32m' + \"Zoomed-in frDNA spread image file saved to \" + '/'.join([output_folder, 'frDNA_len_filt_limited.png']) + '\\033[1;37m')\n",
    "\n",
    "stats.to_csv('/'.join([output_folder, 'frDNA_len_filt_statistics.csv']), index=False)\n",
    "if args.verbose:\n",
    "    print('\\033[0;32m' + \"Summary statistics file saved to \" + '/'.join([output_folder, 'frDNA_len_filt_statistics.csv']) + '\\033[1;37m')\n",
    "    \n",
    "print('\\033[0;35m'+'END'+'\\033[1;37m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
