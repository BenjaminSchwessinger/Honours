{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Z. tritici vs C. globuliformis\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(labels.shape)\n",
    "# print(data.shape)\n",
    "# print(data)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_2 = data[(labels == 2)]\n",
    "# data_class_6 = data[(labels == 6)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_2[50])\n",
    "# print(data_class_6[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_2.shape: ', data_class_2.shape)\n",
    "# print('data_class_6.shape: ', data_class_6.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_2.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_2, data_class_6))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Z. tritici vs P. tritici-repentis\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b3_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b3_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(data.shape)\n",
    "# print(labels.shape)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_2 = data[(labels == 2)]\n",
    "# data_class_3 = data[(labels == 3)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_2[50])\n",
    "# print(data_class_3[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_2.shape: ', data_class_2.shape)\n",
    "# print('data_class_3.shape: ', data_class_3.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_2.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_2, data_class_3))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C. metapsilosis vs C. orthopsilosis\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(labels.shape)\n",
    "# print(data.shape)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_4 = data[(labels == 4)]\n",
    "# data_class_5 = data[(labels == 5)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_4[50])\n",
    "# print(data_class_5[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_4.shape: ', data_class_4.shape)\n",
    "# print('data_class_5.shape: ', data_class_5.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_4.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_4, data_class_5))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.savefig('../../cryptic_4.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C. metapsilosis vs C. orthopsilosis\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_0_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_0_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(labels.shape)\n",
    "# print(data.shape)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_4 = data[(labels == 4)]\n",
    "# data_class_5 = data[(labels == 5)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_4[50])\n",
    "# print(data_class_5[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_4.shape: ', data_class_4.shape)\n",
    "# print('data_class_5.shape: ', data_class_5.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_4.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_4, data_class_5))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.savefig('../../cryptic_0.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C. metapsilosis vs C. orthopsilosis\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_1-4_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_1-4_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(labels.shape)\n",
    "# print(data.shape)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_4 = data[(labels == 4)]\n",
    "# data_class_5 = data[(labels == 5)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_4[50])\n",
    "# print(data_class_5[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_4.shape: ', data_class_4.shape)\n",
    "# print('data_class_5.shape: ', data_class_5.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_4.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_4, data_class_5))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.savefig('../../cryptic_1-4.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # C. albicans vs C. metapsilosis\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(labels.shape)\n",
    "# print(data.shape)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_4 = data[(labels == 4)]\n",
    "# data_class_3 = data[(labels == 3)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_4[50])\n",
    "# print(data_class_3[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_4.shape: ', data_class_4.shape)\n",
    "# print('data_class_3.shape: ', data_class_3.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_4.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_4, data_class_3))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Y. mexicana vs Y. scolyti\n",
    "# %matplotlib inline\n",
    "# import numpy as np\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.utils import plot_model\n",
    "# from PIL import Image\n",
    "# import random\n",
    "# import math\n",
    "# import os\n",
    "# import matplotlib.pyplot as plt\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# # First import the data by loading the file and extracting the correct section\n",
    "# data_npz = np.load('../../analysis/arrays_test/20171207_FAH18654_b7+b8_seqs.csv.npz')\n",
    "# data = data_npz['arr_0']\n",
    "# labels_npz = np.load('../../analysis/arrays_test/20171207_FAH18654_b7+b8_ids.csv.npz')\n",
    "# labels = labels_npz['arr_0']\n",
    "\n",
    "# # Print the shape of the resulting dataframes to visually verify\n",
    "# print(labels.shape)\n",
    "# print(data.shape)\n",
    "\n",
    "# # Separate the data into separate classes based on the labels\n",
    "# data_class_7 = data[(labels == 7)]\n",
    "# data_class_8 = data[(labels == 8)]\n",
    "# # Print an entry to visualise this\n",
    "# print(data_class_7[50])\n",
    "# print(data_class_8[50])\n",
    "\n",
    "# # Print the shape of these new arrays to visually verify\n",
    "# print('data_class_7.shape: ', data_class_7.shape)\n",
    "# print('data_class_8.shape: ', data_class_8.shape)\n",
    "\n",
    "# # Determine the total number of samples per class, and the total number of samples overall\n",
    "# samples_per_class = data_class_7.shape[0]\n",
    "# samples_count = samples_per_class*2\n",
    "# print('samples_per_class: ', samples_per_class)\n",
    "# print('samples_count: ', samples_count)\n",
    "\n",
    "# # Create a vertically stacked arra containing all sequences, then join labels\n",
    "# all_data = np.vstack((data_class_7, data_class_8))\n",
    "# print('all_data.shape : ', all_data.shape)\n",
    "# all_labels = np.hstack( (np.zeros(samples_per_class), np.ones(samples_per_class)) )\n",
    "# print('all_labels.shape : ', all_labels.shape)\n",
    "\n",
    "# # Create a method for shuffling data\n",
    "# shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "# print(len(shuffle_indices))\n",
    "\n",
    "# # Assign a percentage of data for training and the rest for testing\n",
    "# train_size = math.floor(0.85*all_data.shape[0])\n",
    "# indices_train = shuffle_indices[0:train_size]\n",
    "# indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# # Define the data vs labels for each of the training ad test sets\n",
    "# X_train = all_data[indices_train,:]\n",
    "# Y_train = all_labels[indices_train]\n",
    "# X_test = all_data[indices_test,:]\n",
    "# Y_test = all_labels[indices_test]\n",
    "# print('X_train.shape : ', X_train.shape)\n",
    "# print('X_test.shape : ', X_test.shape)\n",
    "# print('Y_train.shape : ', Y_train.shape)\n",
    "# print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# # Define the input dimension from X_train.shape[1]\n",
    "# in_dim = X_train.shape[1]\n",
    "\n",
    "# # define the keras model\n",
    "# #model = Sequential()\n",
    "# #model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "# #model.add(Dense(64, activation='relu'))\n",
    "# #model.add(Dense(32, activation='relu'))\n",
    "# #model.add(Dense(2, activation='softmax'))\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # compile the keras model\n",
    "# #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Run the model\n",
    "# history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using padding 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z. tritici vs C. globuliformis\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_seqs4.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_ids4.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_2 = data[:samples_per_class,:]\n",
    "data_class_6 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_2[50])\n",
    "print(data_class_6[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for Z. tritici vs C. globuliformis (g.d. = 77.7%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using padding 0 with 1-4 for bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z. tritici vs C. globuliformis\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_seqs0.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_ids0.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_2 = data[:samples_per_class,:]\n",
    "data_class_6 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_2[50])\n",
    "print(data_class_6[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for Z. tritici vs C. globuliformis (padding 0, bases 1-4)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using padding 0\n",
    "###### Seems to work just fine!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z. tritici vs C. globuliformis\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_2 = data[:samples_per_class,:]\n",
    "data_class_6 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_2[50])\n",
    "print(data_class_6[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for Z. tritic vs C. globuliformis (padding==A)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puccinia striiformis-tritici vs Zymoseptoria tritici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Puccinia striiformis-tritici vs Zymoseptoria tritici\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b1+b2_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b1+b2_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_1 = data[:samples_per_class,:]\n",
    "data_class_2 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_1[50])\n",
    "print(data_class_2[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_1.shape: ', data_class_1.shape)\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for P. striiformis-tritici vs Z. tritici (g.d. = 75.1%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspergillus niger vs Aspergillus flavus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aspergillus niger vs Aspergillus flavus\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b7+20171207_FAH18654_b12_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b7+20171207_FAH18654_b12_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_7 = data[:samples_per_class,:]\n",
    "data_class_12 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_7[50])\n",
    "print(data_class_12[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_7.shape: ', data_class_7.shape)\n",
    "print('data_class_12.shape: ', data_class_12.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for A. niger vs A. flavus (g.d. = 93.5%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candida albicans vs Candida metapsilosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candida albicans vs Candida metapsilosis\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_3 = data[:samples_per_class,:]\n",
    "data_class_4 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_3[50])\n",
    "print(data_class_4[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_3.shape: ', data_class_3.shape)\n",
    "print('data_class_4.shape: ', data_class_4.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for C. albicans vs C. metapsilosis (g.d. = 91.6%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candida metapsilosis vs Candida orthopsilosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candida metapsilosis vs Candida orthopsilosis\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_4 = data[:samples_per_class,:]\n",
    "data_class_5 = data[samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_4[50])\n",
    "print(data_class_5[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_4.shape: ', data_class_4.shape)\n",
    "print('data_class_5.shape: ', data_class_5.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*2\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for C. albicans vs C. metapsilosis (g.d. = 97.7%)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z. tritici vs C. globuliformis vs Candida albicans\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6+20180108_FAH18647_b3_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20171103_FAH15473_b2+b6+20180108_FAH18647_b3_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_2 = data[:samples_per_class,:]\n",
    "data_class_6 = data[samples_per_class:2*samples_per_class,:]\n",
    "data_class_3 = data[2*samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_2[50])\n",
    "print(data_class_6[50])\n",
    "print(data_class_3[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_2.shape: ', data_class_2.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "print('data_class_3.shape: ', data_class_3.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*3\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for Z. tritici vs C. globuliformis vs C. albicans')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. albicans || metapsilosis || orthopsilosis || parapsilosis || unidentified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_labels_onehot.shape:  (45000, 3)\n",
      "data.shape: (45000, 3505)\n",
      "[1 2 3 ... 4 4 4]\n",
      "[1 3 1 ... 4 4 4]\n",
      "[4 1 3 ... 4 4 4]\n",
      "data_class_4.shape:  (15000, 3505)\n",
      "data_class_5.shape:  (15000, 3505)\n",
      "data_class_6.shape:  (15000, 3505)\n",
      "samples_per_class:  15000\n",
      "samples_count:  45000\n",
      "all_data.shape :  (45000, 3505)\n",
      "all_labels_onehot.shape :  (45000, 3)\n",
      "45000\n",
      "38250\n",
      "X_train.shape :  (38250, 3505)\n",
      "X_test.shape :  (6749, 3505)\n",
      "Y_train.shape :  (38250, 3)\n",
      "Y_test.shape :  (6749, 3)\n",
      "WARNING:tensorflow:From /home/tavish/anaconda3/envs/honours1/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 38250 samples, validate on 6749 samples\n",
      "Epoch 1/100\n",
      "38250/38250 [==============================] - 8s 209us/step - loss: 1.2271 - accuracy: 0.3786 - val_loss: 1.0685 - val_accuracy: 0.4313\n",
      "Epoch 2/100\n",
      "38250/38250 [==============================] - 7s 187us/step - loss: 1.0455 - accuracy: 0.4585 - val_loss: 1.0420 - val_accuracy: 0.3947\n",
      "Epoch 3/100\n",
      "38250/38250 [==============================] - 7s 195us/step - loss: 0.9406 - accuracy: 0.5356 - val_loss: 0.9094 - val_accuracy: 0.5330\n",
      "Epoch 4/100\n",
      "38250/38250 [==============================] - 8s 202us/step - loss: 0.8752 - accuracy: 0.5729 - val_loss: 0.8775 - val_accuracy: 0.5547\n",
      "Epoch 5/100\n",
      "38250/38250 [==============================] - 7s 188us/step - loss: 0.8544 - accuracy: 0.5830 - val_loss: 0.8458 - val_accuracy: 0.5768\n",
      "Epoch 6/100\n",
      "38250/38250 [==============================] - 7s 186us/step - loss: 0.8022 - accuracy: 0.6174 - val_loss: 0.8015 - val_accuracy: 0.6219\n",
      "Epoch 7/100\n",
      "38250/38250 [==============================] - 7s 189us/step - loss: 0.7657 - accuracy: 0.6355 - val_loss: 0.7799 - val_accuracy: 0.6250\n",
      "Epoch 8/100\n",
      "38250/38250 [==============================] - 7s 181us/step - loss: 0.7497 - accuracy: 0.6367 - val_loss: 0.7818 - val_accuracy: 0.5982\n",
      "Epoch 9/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.7424 - accuracy: 0.6458 - val_loss: 0.8336 - val_accuracy: 0.5820\n",
      "Epoch 10/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.7335 - accuracy: 0.6546 - val_loss: 0.7603 - val_accuracy: 0.6365\n",
      "Epoch 11/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.7354 - accuracy: 0.6539 - val_loss: 0.8662 - val_accuracy: 0.5845\n",
      "Epoch 12/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.7286 - accuracy: 0.6503 - val_loss: 0.7679 - val_accuracy: 0.6351\n",
      "Epoch 13/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.7130 - accuracy: 0.6702 - val_loss: 0.7621 - val_accuracy: 0.6416\n",
      "Epoch 14/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.7087 - accuracy: 0.6676 - val_loss: 0.8829 - val_accuracy: 0.5559\n",
      "Epoch 15/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.7019 - accuracy: 0.6727 - val_loss: 0.8774 - val_accuracy: 0.5884\n",
      "Epoch 16/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.7157 - accuracy: 0.6683 - val_loss: 0.8536 - val_accuracy: 0.5956\n",
      "Epoch 17/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.6892 - accuracy: 0.6810 - val_loss: 0.9129 - val_accuracy: 0.5721\n",
      "Epoch 18/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.7073 - accuracy: 0.6699 - val_loss: 0.7943 - val_accuracy: 0.6213\n",
      "Epoch 19/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.7003 - accuracy: 0.6702 - val_loss: 0.7557 - val_accuracy: 0.6484\n",
      "Epoch 20/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6899 - accuracy: 0.6806 - val_loss: 0.8440 - val_accuracy: 0.6113\n",
      "Epoch 21/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6887 - accuracy: 0.6790 - val_loss: 0.7866 - val_accuracy: 0.6214\n",
      "Epoch 22/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.6870 - accuracy: 0.6807 - val_loss: 0.7649 - val_accuracy: 0.6410\n",
      "Epoch 23/100\n",
      "38250/38250 [==============================] - 8s 208us/step - loss: 0.6840 - accuracy: 0.6795 - val_loss: 0.7587 - val_accuracy: 0.6371\n",
      "Epoch 24/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6670 - accuracy: 0.6838 - val_loss: 0.7616 - val_accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6878 - accuracy: 0.6784 - val_loss: 0.7681 - val_accuracy: 0.6367\n",
      "Epoch 26/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.6998 - accuracy: 0.6764 - val_loss: 0.8364 - val_accuracy: 0.6088\n",
      "Epoch 27/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.6692 - accuracy: 0.6916 - val_loss: 0.7701 - val_accuracy: 0.6386\n",
      "Epoch 28/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6816 - accuracy: 0.6768 - val_loss: 0.7348 - val_accuracy: 0.6508\n",
      "Epoch 29/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.6669 - accuracy: 0.6863 - val_loss: 0.7369 - val_accuracy: 0.6509\n",
      "Epoch 30/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.6518 - accuracy: 0.6933 - val_loss: 0.7380 - val_accuracy: 0.6482\n",
      "Epoch 31/100\n",
      "38250/38250 [==============================] - 8s 213us/step - loss: 0.6882 - accuracy: 0.6754 - val_loss: 0.7937 - val_accuracy: 0.6164\n",
      "Epoch 32/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6529 - accuracy: 0.6915 - val_loss: 0.8167 - val_accuracy: 0.6102\n",
      "Epoch 33/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.6609 - accuracy: 0.6875 - val_loss: 0.9088 - val_accuracy: 0.5817\n",
      "Epoch 34/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6523 - accuracy: 0.6910 - val_loss: 0.8298 - val_accuracy: 0.6210\n",
      "Epoch 35/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6604 - accuracy: 0.6856 - val_loss: 0.8220 - val_accuracy: 0.6309\n",
      "Epoch 36/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.6404 - accuracy: 0.6960 - val_loss: 0.7382 - val_accuracy: 0.6425\n",
      "Epoch 37/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6555 - accuracy: 0.6878 - val_loss: 0.7286 - val_accuracy: 0.6429\n",
      "Epoch 38/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.6393 - accuracy: 0.6972 - val_loss: 0.7246 - val_accuracy: 0.6485\n",
      "Epoch 39/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6387 - accuracy: 0.6958 - val_loss: 0.7446 - val_accuracy: 0.6342\n",
      "Epoch 40/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.6383 - accuracy: 0.6935 - val_loss: 0.7622 - val_accuracy: 0.6519\n",
      "Epoch 41/100\n",
      "38250/38250 [==============================] - 8s 212us/step - loss: 0.6430 - accuracy: 0.6950 - val_loss: 0.7493 - val_accuracy: 0.6454\n",
      "Epoch 42/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.6299 - accuracy: 0.6992 - val_loss: 0.7266 - val_accuracy: 0.6561\n",
      "Epoch 43/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.6231 - accuracy: 0.7057 - val_loss: 0.8184 - val_accuracy: 0.6514\n",
      "Epoch 44/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.6102 - accuracy: 0.7114 - val_loss: 0.7277 - val_accuracy: 0.6644\n",
      "Epoch 45/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5995 - accuracy: 0.7163 - val_loss: 0.7616 - val_accuracy: 0.6211\n",
      "Epoch 46/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.6214 - accuracy: 0.7036 - val_loss: 0.7317 - val_accuracy: 0.6490\n",
      "Epoch 47/100\n",
      "38250/38250 [==============================] - 8s 212us/step - loss: 0.6093 - accuracy: 0.7118 - val_loss: 0.7870 - val_accuracy: 0.6330\n",
      "Epoch 48/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.6307 - accuracy: 0.6980 - val_loss: 0.7602 - val_accuracy: 0.6481\n",
      "Epoch 49/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5917 - accuracy: 0.7178 - val_loss: 0.7207 - val_accuracy: 0.6628\n",
      "Epoch 50/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5952 - accuracy: 0.7170 - val_loss: 0.7329 - val_accuracy: 0.6631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5993 - accuracy: 0.7147 - val_loss: 0.8208 - val_accuracy: 0.6351\n",
      "Epoch 52/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5969 - accuracy: 0.7146 - val_loss: 0.7219 - val_accuracy: 0.6623\n",
      "Epoch 53/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5961 - accuracy: 0.7189 - val_loss: 0.8948 - val_accuracy: 0.5879\n",
      "Epoch 54/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.5849 - accuracy: 0.7206 - val_loss: 0.8057 - val_accuracy: 0.6509\n",
      "Epoch 55/100\n",
      "38250/38250 [==============================] - 8s 208us/step - loss: 0.5727 - accuracy: 0.7274 - val_loss: 0.7210 - val_accuracy: 0.6554\n",
      "Epoch 56/100\n",
      "38250/38250 [==============================] - 8s 210us/step - loss: 0.5645 - accuracy: 0.7320 - val_loss: 0.7218 - val_accuracy: 0.6496\n",
      "Epoch 57/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5722 - accuracy: 0.7278 - val_loss: 0.9707 - val_accuracy: 0.6460\n",
      "Epoch 58/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5731 - accuracy: 0.7288 - val_loss: 0.7998 - val_accuracy: 0.6434\n",
      "Epoch 59/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5746 - accuracy: 0.7277 - val_loss: 0.7255 - val_accuracy: 0.6665\n",
      "Epoch 60/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.5697 - accuracy: 0.7284 - val_loss: 0.7573 - val_accuracy: 0.6468\n",
      "Epoch 61/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5662 - accuracy: 0.7277 - val_loss: 0.7628 - val_accuracy: 0.6512\n",
      "Epoch 62/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5610 - accuracy: 0.7302 - val_loss: 0.7504 - val_accuracy: 0.6742\n",
      "Epoch 63/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5687 - accuracy: 0.7267 - val_loss: 0.7392 - val_accuracy: 0.6586\n",
      "Epoch 64/100\n",
      "38250/38250 [==============================] - 8s 213us/step - loss: 0.5489 - accuracy: 0.7401 - val_loss: 0.7216 - val_accuracy: 0.6597\n",
      "Epoch 65/100\n",
      "38250/38250 [==============================] - 8s 212us/step - loss: 0.5542 - accuracy: 0.7387 - val_loss: 0.8467 - val_accuracy: 0.6137\n",
      "Epoch 66/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5463 - accuracy: 0.7422 - val_loss: 0.7912 - val_accuracy: 0.6699\n",
      "Epoch 67/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.5587 - accuracy: 0.7314 - val_loss: 0.8375 - val_accuracy: 0.6183\n",
      "Epoch 68/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5290 - accuracy: 0.7482 - val_loss: 0.8236 - val_accuracy: 0.6645\n",
      "Epoch 69/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5413 - accuracy: 0.7416 - val_loss: 0.7785 - val_accuracy: 0.6653\n",
      "Epoch 70/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5392 - accuracy: 0.7419 - val_loss: 0.8704 - val_accuracy: 0.6419\n",
      "Epoch 71/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5369 - accuracy: 0.7416 - val_loss: 0.8817 - val_accuracy: 0.6445\n",
      "Epoch 72/100\n",
      "38250/38250 [==============================] - 8s 211us/step - loss: 0.5392 - accuracy: 0.7399 - val_loss: 0.7688 - val_accuracy: 0.6442\n",
      "Epoch 73/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5337 - accuracy: 0.7439 - val_loss: 0.7387 - val_accuracy: 0.6690\n",
      "Epoch 74/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5307 - accuracy: 0.7469 - val_loss: 0.9511 - val_accuracy: 0.6558\n",
      "Epoch 75/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5171 - accuracy: 0.7533 - val_loss: 0.7477 - val_accuracy: 0.6690\n",
      "Epoch 76/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5089 - accuracy: 0.7545 - val_loss: 0.7381 - val_accuracy: 0.6688\n",
      "Epoch 77/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.5229 - accuracy: 0.7482 - val_loss: 0.7532 - val_accuracy: 0.6669\n",
      "Epoch 78/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.5209 - accuracy: 0.7494 - val_loss: 0.7760 - val_accuracy: 0.6616\n",
      "Epoch 79/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5295 - accuracy: 0.7456 - val_loss: 0.7495 - val_accuracy: 0.6561\n",
      "Epoch 80/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5174 - accuracy: 0.7496 - val_loss: 0.8715 - val_accuracy: 0.6542\n",
      "Epoch 81/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5042 - accuracy: 0.7551 - val_loss: 0.7586 - val_accuracy: 0.6635\n",
      "Epoch 82/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5160 - accuracy: 0.7518 - val_loss: 0.7699 - val_accuracy: 0.6684\n",
      "Epoch 83/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.4964 - accuracy: 0.7588 - val_loss: 0.7916 - val_accuracy: 0.6675\n",
      "Epoch 84/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5066 - accuracy: 0.7535 - val_loss: 0.8238 - val_accuracy: 0.6533\n",
      "Epoch 85/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5053 - accuracy: 0.7563 - val_loss: 0.7630 - val_accuracy: 0.6376\n",
      "Epoch 86/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.5028 - accuracy: 0.7581 - val_loss: 0.8474 - val_accuracy: 0.6367\n",
      "Epoch 87/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.4875 - accuracy: 0.7645 - val_loss: 0.8032 - val_accuracy: 0.6712\n",
      "Epoch 88/100\n",
      "38250/38250 [==============================] - 8s 213us/step - loss: 0.4977 - accuracy: 0.7565 - val_loss: 0.7970 - val_accuracy: 0.6660\n",
      "Epoch 89/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.4816 - accuracy: 0.7664 - val_loss: 0.8213 - val_accuracy: 0.6634\n",
      "Epoch 90/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.4818 - accuracy: 0.7667 - val_loss: 0.7700 - val_accuracy: 0.6604\n",
      "Epoch 91/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.4909 - accuracy: 0.7623 - val_loss: 0.8822 - val_accuracy: 0.6743\n",
      "Epoch 92/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.4666 - accuracy: 0.7723 - val_loss: 0.8884 - val_accuracy: 0.6576\n",
      "Epoch 93/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.4730 - accuracy: 0.7714 - val_loss: 0.8367 - val_accuracy: 0.6721\n",
      "Epoch 94/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.4807 - accuracy: 0.7672 - val_loss: 0.7832 - val_accuracy: 0.6620\n",
      "Epoch 95/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.4642 - accuracy: 0.7757 - val_loss: 0.8723 - val_accuracy: 0.6081\n",
      "Epoch 96/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.4808 - accuracy: 0.7663 - val_loss: 0.8363 - val_accuracy: 0.6648\n",
      "Epoch 97/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.4633 - accuracy: 0.7741 - val_loss: 0.8911 - val_accuracy: 0.6530\n",
      "Epoch 98/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.4792 - accuracy: 0.7695 - val_loss: 0.9621 - val_accuracy: 0.6583\n",
      "Epoch 99/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.4565 - accuracy: 0.7770 - val_loss: 0.8234 - val_accuracy: 0.6641\n",
      "Epoch 100/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.4584 - accuracy: 0.7755 - val_loss: 0.8413 - val_accuracy: 0.6691\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cryptic Candida\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5+b6_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b4+b5+b6_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "num_class = 3\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_4 = data[:samples_per_class,:]\n",
    "data_class_5 = data[samples_per_class:2*samples_per_class,:]\n",
    "data_class_6 = data[2*samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_4[50])\n",
    "print(data_class_5[50])\n",
    "print(data_class_6[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_4.shape: ', data_class_4.shape)\n",
    "print('data_class_5.shape: ', data_class_5.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*num_class\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_class, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for Cryptic Candida')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_labels_onehot.shape:  (45000, 3)\n",
      "data.shape: (45000, 4352)\n",
      "[1 1 3 ... 4 4 4]\n",
      "[3 1 4 ... 4 4 4]\n",
      "[2 1 3 ... 4 4 4]\n",
      "data_class_3.shape:  (15000, 4352)\n",
      "data_class_5.shape:  (15000, 4352)\n",
      "data_class_9.shape:  (15000, 4352)\n",
      "samples_per_class:  15000\n",
      "samples_count:  45000\n",
      "all_data.shape :  (45000, 4352)\n",
      "all_labels_onehot.shape :  (45000, 3)\n",
      "45000\n",
      "38250\n",
      "X_train.shape :  (38250, 4352)\n",
      "X_test.shape :  (6749, 4352)\n",
      "Y_train.shape :  (38250, 3)\n",
      "Y_test.shape :  (6749, 3)\n",
      "Train on 38250 samples, validate on 6749 samples\n",
      "Epoch 1/100\n",
      "38250/38250 [==============================] - 8s 202us/step - loss: 1.1989 - accuracy: 0.4030 - val_loss: 1.0032 - val_accuracy: 0.4866\n",
      "Epoch 2/100\n",
      "38250/38250 [==============================] - 7s 196us/step - loss: 0.9824 - accuracy: 0.5109 - val_loss: 0.9286 - val_accuracy: 0.5457\n",
      "Epoch 3/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.9187 - accuracy: 0.5597 - val_loss: 0.8727 - val_accuracy: 0.5913\n",
      "Epoch 4/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.8400 - accuracy: 0.6092 - val_loss: 0.9077 - val_accuracy: 0.5392\n",
      "Epoch 5/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.7860 - accuracy: 0.6396 - val_loss: 0.8815 - val_accuracy: 0.5703\n",
      "Epoch 6/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.7385 - accuracy: 0.6680 - val_loss: 0.7348 - val_accuracy: 0.6595\n",
      "Epoch 7/100\n",
      "38250/38250 [==============================] - 8s 217us/step - loss: 0.7328 - accuracy: 0.6718 - val_loss: 0.7451 - val_accuracy: 0.6623\n",
      "Epoch 8/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.6968 - accuracy: 0.6898 - val_loss: 0.6992 - val_accuracy: 0.6899\n",
      "Epoch 9/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.6986 - accuracy: 0.6924 - val_loss: 0.6872 - val_accuracy: 0.6986\n",
      "Epoch 10/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.6761 - accuracy: 0.7053 - val_loss: 0.7074 - val_accuracy: 0.6862\n",
      "Epoch 11/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.6716 - accuracy: 0.7063 - val_loss: 0.7187 - val_accuracy: 0.6767\n",
      "Epoch 12/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.6910 - accuracy: 0.6982 - val_loss: 0.7241 - val_accuracy: 0.6802\n",
      "Epoch 13/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.6549 - accuracy: 0.7135 - val_loss: 0.6792 - val_accuracy: 0.7011\n",
      "Epoch 14/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.6432 - accuracy: 0.7208 - val_loss: 0.7194 - val_accuracy: 0.6822\n",
      "Epoch 15/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.6299 - accuracy: 0.7309 - val_loss: 0.7047 - val_accuracy: 0.7019\n",
      "Epoch 16/100\n",
      "38250/38250 [==============================] - 9s 228us/step - loss: 0.6391 - accuracy: 0.7217 - val_loss: 0.7485 - val_accuracy: 0.6688\n",
      "Epoch 17/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.6422 - accuracy: 0.7212 - val_loss: 0.6869 - val_accuracy: 0.7011\n",
      "Epoch 18/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.6405 - accuracy: 0.7234 - val_loss: 0.6787 - val_accuracy: 0.7081\n",
      "Epoch 19/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.6391 - accuracy: 0.7218 - val_loss: 0.7481 - val_accuracy: 0.6844\n",
      "Epoch 20/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.6219 - accuracy: 0.7336 - val_loss: 0.7191 - val_accuracy: 0.6838\n",
      "Epoch 21/100\n",
      "38250/38250 [==============================] - 9s 226us/step - loss: 0.6318 - accuracy: 0.7288 - val_loss: 0.7172 - val_accuracy: 0.6983\n",
      "Epoch 22/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.6391 - accuracy: 0.7239 - val_loss: 0.7190 - val_accuracy: 0.6832\n",
      "Epoch 23/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.6232 - accuracy: 0.7336 - val_loss: 0.7892 - val_accuracy: 0.6757\n",
      "Epoch 24/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.6218 - accuracy: 0.7355 - val_loss: 0.7314 - val_accuracy: 0.6936\n",
      "Epoch 25/100\n",
      "38250/38250 [==============================] - 9s 226us/step - loss: 0.6221 - accuracy: 0.7348 - val_loss: 0.7821 - val_accuracy: 0.6782\n",
      "Epoch 26/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.6145 - accuracy: 0.7359 - val_loss: 0.6849 - val_accuracy: 0.7071\n",
      "Epoch 27/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.6052 - accuracy: 0.7423 - val_loss: 0.7001 - val_accuracy: 0.6940\n",
      "Epoch 28/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.6054 - accuracy: 0.7402 - val_loss: 0.6902 - val_accuracy: 0.7056\n",
      "Epoch 29/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.6238 - accuracy: 0.7339 - val_loss: 0.6922 - val_accuracy: 0.7080\n",
      "Epoch 30/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.6137 - accuracy: 0.7351 - val_loss: 0.9369 - val_accuracy: 0.6068\n",
      "Epoch 31/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.6097 - accuracy: 0.7378 - val_loss: 0.6837 - val_accuracy: 0.6995\n",
      "Epoch 32/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.6098 - accuracy: 0.7381 - val_loss: 0.6776 - val_accuracy: 0.7123\n",
      "Epoch 33/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5955 - accuracy: 0.7456 - val_loss: 0.7145 - val_accuracy: 0.6902\n",
      "Epoch 34/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5875 - accuracy: 0.7491 - val_loss: 0.7228 - val_accuracy: 0.6911\n",
      "Epoch 35/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5938 - accuracy: 0.7436 - val_loss: 0.7406 - val_accuracy: 0.6745\n",
      "Epoch 36/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5952 - accuracy: 0.7442 - val_loss: 0.7956 - val_accuracy: 0.6625\n",
      "Epoch 37/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5867 - accuracy: 0.7482 - val_loss: 0.7153 - val_accuracy: 0.6823\n",
      "Epoch 38/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.5841 - accuracy: 0.7488 - val_loss: 0.7023 - val_accuracy: 0.7041\n",
      "Epoch 39/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5972 - accuracy: 0.7416 - val_loss: 0.6634 - val_accuracy: 0.7146\n",
      "Epoch 40/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5882 - accuracy: 0.7476 - val_loss: 0.6928 - val_accuracy: 0.6992\n",
      "Epoch 41/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5809 - accuracy: 0.7479 - val_loss: 0.6526 - val_accuracy: 0.7139\n",
      "Epoch 42/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5889 - accuracy: 0.7442 - val_loss: 0.6576 - val_accuracy: 0.7148\n",
      "Epoch 43/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5806 - accuracy: 0.7478 - val_loss: 0.6872 - val_accuracy: 0.6989\n",
      "Epoch 44/100\n",
      "38250/38250 [==============================] - 9s 222us/step - loss: 0.5717 - accuracy: 0.7520 - val_loss: 0.6889 - val_accuracy: 0.7011\n",
      "Epoch 45/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5656 - accuracy: 0.7539 - val_loss: 0.6645 - val_accuracy: 0.7080\n",
      "Epoch 46/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5744 - accuracy: 0.7510 - val_loss: 0.6566 - val_accuracy: 0.7148\n",
      "Epoch 47/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5629 - accuracy: 0.7573 - val_loss: 0.6678 - val_accuracy: 0.7151\n",
      "Epoch 48/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.5610 - accuracy: 0.7557 - val_loss: 0.6975 - val_accuracy: 0.6977\n",
      "Epoch 49/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5567 - accuracy: 0.7588 - val_loss: 0.7125 - val_accuracy: 0.6997\n",
      "Epoch 50/100\n",
      "38250/38250 [==============================] - 8s 218us/step - loss: 0.5492 - accuracy: 0.7620 - val_loss: 0.6564 - val_accuracy: 0.7060\n",
      "Epoch 51/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5607 - accuracy: 0.7594 - val_loss: 0.6549 - val_accuracy: 0.7128\n",
      "Epoch 52/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5490 - accuracy: 0.7611 - val_loss: 0.6692 - val_accuracy: 0.7114\n",
      "Epoch 53/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.5568 - accuracy: 0.7600 - val_loss: 0.6789 - val_accuracy: 0.7177\n",
      "Epoch 54/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5411 - accuracy: 0.7656 - val_loss: 0.7588 - val_accuracy: 0.6783\n",
      "Epoch 55/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5466 - accuracy: 0.7644 - val_loss: 0.7376 - val_accuracy: 0.6874\n",
      "Epoch 56/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5458 - accuracy: 0.7652 - val_loss: 0.6445 - val_accuracy: 0.7217\n",
      "Epoch 57/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5419 - accuracy: 0.7656 - val_loss: 0.6586 - val_accuracy: 0.7157\n",
      "Epoch 58/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5333 - accuracy: 0.7701 - val_loss: 0.6663 - val_accuracy: 0.7240\n",
      "Epoch 59/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5604 - accuracy: 0.7552 - val_loss: 0.7130 - val_accuracy: 0.6934\n",
      "Epoch 60/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5455 - accuracy: 0.7648 - val_loss: 0.8176 - val_accuracy: 0.6699\n",
      "Epoch 61/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5350 - accuracy: 0.7684 - val_loss: 0.7176 - val_accuracy: 0.6998\n",
      "Epoch 62/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5396 - accuracy: 0.7662 - val_loss: 0.7550 - val_accuracy: 0.6863\n",
      "Epoch 63/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5337 - accuracy: 0.7692 - val_loss: 0.6872 - val_accuracy: 0.7016\n",
      "Epoch 64/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5417 - accuracy: 0.7650 - val_loss: 0.9459 - val_accuracy: 0.6121\n",
      "Epoch 65/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.5278 - accuracy: 0.7711 - val_loss: 0.7620 - val_accuracy: 0.6884\n",
      "Epoch 66/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5350 - accuracy: 0.7662 - val_loss: 0.7510 - val_accuracy: 0.6814\n",
      "Epoch 67/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5426 - accuracy: 0.7647 - val_loss: 0.7018 - val_accuracy: 0.7007\n",
      "Epoch 68/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.5262 - accuracy: 0.7740 - val_loss: 0.6805 - val_accuracy: 0.7143\n",
      "Epoch 69/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5268 - accuracy: 0.7726 - val_loss: 0.6485 - val_accuracy: 0.7220\n",
      "Epoch 70/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5253 - accuracy: 0.7735 - val_loss: 0.7347 - val_accuracy: 0.6755\n",
      "Epoch 71/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5238 - accuracy: 0.7721 - val_loss: 0.6677 - val_accuracy: 0.7152\n",
      "Epoch 72/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5253 - accuracy: 0.7737 - val_loss: 0.7133 - val_accuracy: 0.7028\n",
      "Epoch 73/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.5174 - accuracy: 0.7757 - val_loss: 0.6581 - val_accuracy: 0.7225\n",
      "Epoch 74/100\n",
      "38250/38250 [==============================] - 8s 216us/step - loss: 0.5140 - accuracy: 0.7772 - val_loss: 0.6626 - val_accuracy: 0.7180\n",
      "Epoch 75/100\n",
      "38250/38250 [==============================] - 9s 225us/step - loss: 0.5251 - accuracy: 0.7718 - val_loss: 0.8207 - val_accuracy: 0.6453\n",
      "Epoch 76/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5230 - accuracy: 0.7712 - val_loss: 0.6647 - val_accuracy: 0.7112\n",
      "Epoch 77/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5131 - accuracy: 0.7793 - val_loss: 0.7896 - val_accuracy: 0.6755\n",
      "Epoch 78/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5088 - accuracy: 0.7810 - val_loss: 0.6629 - val_accuracy: 0.7180\n",
      "Epoch 79/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5107 - accuracy: 0.7774 - val_loss: 0.6796 - val_accuracy: 0.7176\n",
      "Epoch 80/100\n",
      "38250/38250 [==============================] - 8s 214us/step - loss: 0.5072 - accuracy: 0.7806 - val_loss: 0.6671 - val_accuracy: 0.7168\n",
      "Epoch 81/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5147 - accuracy: 0.7786 - val_loss: 0.7076 - val_accuracy: 0.7182\n",
      "Epoch 82/100\n",
      "38250/38250 [==============================] - 9s 222us/step - loss: 0.5000 - accuracy: 0.7839 - val_loss: 0.7292 - val_accuracy: 0.6937\n",
      "Epoch 83/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.5035 - accuracy: 0.7827 - val_loss: 0.7046 - val_accuracy: 0.7065\n",
      "Epoch 84/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5095 - accuracy: 0.7797 - val_loss: 0.7182 - val_accuracy: 0.7106\n",
      "Epoch 85/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5111 - accuracy: 0.7807 - val_loss: 0.6698 - val_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5073 - accuracy: 0.7798 - val_loss: 0.6901 - val_accuracy: 0.7161\n",
      "Epoch 87/100\n",
      "38250/38250 [==============================] - 9s 222us/step - loss: 0.5033 - accuracy: 0.7811 - val_loss: 0.6853 - val_accuracy: 0.7210\n",
      "Epoch 88/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5024 - accuracy: 0.7824 - val_loss: 0.7118 - val_accuracy: 0.6868\n",
      "Epoch 89/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.5105 - accuracy: 0.7778 - val_loss: 0.6883 - val_accuracy: 0.7154\n",
      "Epoch 90/100\n",
      "38250/38250 [==============================] - 9s 222us/step - loss: 0.5000 - accuracy: 0.7841 - val_loss: 0.6776 - val_accuracy: 0.7207\n",
      "Epoch 91/100\n",
      "38250/38250 [==============================] - 8s 215us/step - loss: 0.4869 - accuracy: 0.7907 - val_loss: 0.6802 - val_accuracy: 0.7125\n",
      "Epoch 92/100\n",
      "38250/38250 [==============================] - 9s 223us/step - loss: 0.4989 - accuracy: 0.7861 - val_loss: 0.7367 - val_accuracy: 0.6998\n",
      "Epoch 93/100\n",
      "38250/38250 [==============================] - 8s 222us/step - loss: 0.5076 - accuracy: 0.7808 - val_loss: 0.7114 - val_accuracy: 0.7019\n",
      "Epoch 94/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.4958 - accuracy: 0.7856 - val_loss: 0.6994 - val_accuracy: 0.7148\n",
      "Epoch 95/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.4857 - accuracy: 0.7929 - val_loss: 0.7055 - val_accuracy: 0.7168\n",
      "Epoch 96/100\n",
      "38250/38250 [==============================] - 8s 220us/step - loss: 0.5021 - accuracy: 0.7848 - val_loss: 0.7236 - val_accuracy: 0.7096\n",
      "Epoch 97/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.5015 - accuracy: 0.7834 - val_loss: 0.7964 - val_accuracy: 0.6854\n",
      "Epoch 98/100\n",
      "38250/38250 [==============================] - 8s 221us/step - loss: 0.4972 - accuracy: 0.7856 - val_loss: 0.7596 - val_accuracy: 0.7093\n",
      "Epoch 99/100\n",
      "38250/38250 [==============================] - 9s 224us/step - loss: 0.4852 - accuracy: 0.7919 - val_loss: 0.7291 - val_accuracy: 0.7176\n",
      "Epoch 100/100\n",
      "38250/38250 [==============================] - 8s 219us/step - loss: 0.4884 - accuracy: 0.7901 - val_loss: 0.7030 - val_accuracy: 0.7069\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Candida albicans vs Candida orthopsilosis vs Candida unidentified\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b5+b9_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b5+b9_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "num_class = 3\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_3 = data[:samples_per_class,:]\n",
    "data_class_5 = data[samples_per_class:2*samples_per_class,:]\n",
    "data_class_9 = data[2*samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_3[50])\n",
    "print(data_class_5[50])\n",
    "print(data_class_9[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_3.shape: ', data_class_3.shape)\n",
    "print('data_class_5.shape: ', data_class_5.shape)\n",
    "print('data_class_9.shape: ', data_class_9.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*num_class\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_class, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for C. albicans vs orthopsilosis vs unidentified')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_labels_onehot.shape:  (75000, 5)\n",
      "data.shape: (75000, 4352)\n",
      "[3 1 2 ... 4 4 4]\n",
      "[2 3 4 ... 4 4 4]\n",
      "[3 3 4 ... 4 4 4]\n",
      "[3 4 4 ... 4 4 4]\n",
      "[3 1 2 ... 4 4 4]\n",
      "data_class_3.shape:  (15000, 4352)\n",
      "data_class_4.shape:  (15000, 4352)\n",
      "data_class_5.shape:  (15000, 4352)\n",
      "data_class_6.shape:  (15000, 4352)\n",
      "data_class_9.shape:  (15000, 4352)\n",
      "samples_per_class:  15000\n",
      "samples_count:  75000\n",
      "all_data.shape :  (75000, 4352)\n",
      "all_labels_onehot.shape :  (75000, 5)\n",
      "75000\n",
      "63750\n",
      "X_train.shape :  (63750, 4352)\n",
      "X_test.shape :  (11249, 4352)\n",
      "Y_train.shape :  (63750, 5)\n",
      "Y_test.shape :  (11249, 5)\n",
      "Train on 63750 samples, validate on 11249 samples\n",
      "Epoch 1/100\n",
      "63750/63750 [==============================] - 4s 61us/step - loss: 1.7034 - accuracy: 0.2324 - val_loss: 1.5733 - val_accuracy: 0.2390\n",
      "Epoch 2/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 1.5568 - accuracy: 0.2749 - val_loss: 1.5138 - val_accuracy: 0.3037\n",
      "Epoch 3/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.4741 - accuracy: 0.3359 - val_loss: 1.5055 - val_accuracy: 0.3086\n",
      "Epoch 4/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.3507 - accuracy: 0.4049 - val_loss: 1.2644 - val_accuracy: 0.4425\n",
      "Epoch 5/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.2434 - accuracy: 0.4588 - val_loss: 1.2378 - val_accuracy: 0.4632\n",
      "Epoch 6/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.1504 - accuracy: 0.4987 - val_loss: 1.1352 - val_accuracy: 0.5067\n",
      "Epoch 7/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.1260 - accuracy: 0.5047 - val_loss: 1.4181 - val_accuracy: 0.4225\n",
      "Epoch 8/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.0976 - accuracy: 0.5161 - val_loss: 1.0755 - val_accuracy: 0.5264\n",
      "Epoch 9/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0849 - accuracy: 0.5171 - val_loss: 1.0735 - val_accuracy: 0.5212\n",
      "Epoch 10/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.0705 - accuracy: 0.5233 - val_loss: 1.1602 - val_accuracy: 0.4926\n",
      "Epoch 11/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0605 - accuracy: 0.5281 - val_loss: 1.0445 - val_accuracy: 0.5364\n",
      "Epoch 12/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0481 - accuracy: 0.5318 - val_loss: 1.0755 - val_accuracy: 0.5264\n",
      "Epoch 13/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0368 - accuracy: 0.5386 - val_loss: 1.0543 - val_accuracy: 0.5246\n",
      "Epoch 14/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0486 - accuracy: 0.5347 - val_loss: 1.1123 - val_accuracy: 0.5026\n",
      "Epoch 15/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0250 - accuracy: 0.5415 - val_loss: 1.1135 - val_accuracy: 0.5096\n",
      "Epoch 16/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.0148 - accuracy: 0.5460 - val_loss: 1.1024 - val_accuracy: 0.5105\n",
      "Epoch 17/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.0242 - accuracy: 0.5400 - val_loss: 1.0227 - val_accuracy: 0.5426\n",
      "Epoch 18/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.0337 - accuracy: 0.5350 - val_loss: 1.0222 - val_accuracy: 0.5422\n",
      "Epoch 19/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0048 - accuracy: 0.5484 - val_loss: 1.0682 - val_accuracy: 0.5240\n",
      "Epoch 20/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 1.0189 - accuracy: 0.5427 - val_loss: 1.0304 - val_accuracy: 0.5408\n",
      "Epoch 21/100\n",
      "63750/63750 [==============================] - 4s 61us/step - loss: 1.0044 - accuracy: 0.5481 - val_loss: 1.1020 - val_accuracy: 0.5136\n",
      "Epoch 22/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9994 - accuracy: 0.5511 - val_loss: 1.0365 - val_accuracy: 0.5337\n",
      "Epoch 23/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 1.0028 - accuracy: 0.5508 - val_loss: 1.1977 - val_accuracy: 0.4881\n",
      "Epoch 24/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9922 - accuracy: 0.5555 - val_loss: 1.0597 - val_accuracy: 0.5291\n",
      "Epoch 25/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9952 - accuracy: 0.5525 - val_loss: 1.0368 - val_accuracy: 0.5346\n",
      "Epoch 26/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9884 - accuracy: 0.5576 - val_loss: 1.0175 - val_accuracy: 0.5419\n",
      "Epoch 27/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9851 - accuracy: 0.5574 - val_loss: 1.0372 - val_accuracy: 0.5372\n",
      "Epoch 28/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9888 - accuracy: 0.5532 - val_loss: 1.0475 - val_accuracy: 0.5344\n",
      "Epoch 29/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9903 - accuracy: 0.5555 - val_loss: 1.0709 - val_accuracy: 0.5192\n",
      "Epoch 30/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9960 - accuracy: 0.5544 - val_loss: 1.1584 - val_accuracy: 0.4917\n",
      "Epoch 31/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9751 - accuracy: 0.5604 - val_loss: 1.3068 - val_accuracy: 0.4380\n",
      "Epoch 32/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9788 - accuracy: 0.5630 - val_loss: 1.0150 - val_accuracy: 0.5420\n",
      "Epoch 33/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9792 - accuracy: 0.5582 - val_loss: 1.0084 - val_accuracy: 0.5429\n",
      "Epoch 34/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9775 - accuracy: 0.5615 - val_loss: 1.0543 - val_accuracy: 0.5424\n",
      "Epoch 35/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9714 - accuracy: 0.5636 - val_loss: 1.0171 - val_accuracy: 0.5419\n",
      "Epoch 36/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9703 - accuracy: 0.5651 - val_loss: 1.0363 - val_accuracy: 0.5358\n",
      "Epoch 37/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9789 - accuracy: 0.5621 - val_loss: 1.0212 - val_accuracy: 0.5386\n",
      "Epoch 38/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9590 - accuracy: 0.5665 - val_loss: 1.0319 - val_accuracy: 0.5368\n",
      "Epoch 39/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9653 - accuracy: 0.5654 - val_loss: 1.0143 - val_accuracy: 0.5394\n",
      "Epoch 40/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9548 - accuracy: 0.5709 - val_loss: 1.0120 - val_accuracy: 0.5478\n",
      "Epoch 41/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9650 - accuracy: 0.5647 - val_loss: 1.0097 - val_accuracy: 0.5447\n",
      "Epoch 42/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9613 - accuracy: 0.5662 - val_loss: 1.0633 - val_accuracy: 0.5275\n",
      "Epoch 43/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9632 - accuracy: 0.5663 - val_loss: 1.0000 - val_accuracy: 0.5460\n",
      "Epoch 44/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9531 - accuracy: 0.5706 - val_loss: 1.0421 - val_accuracy: 0.5319\n",
      "Epoch 45/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9594 - accuracy: 0.5672 - val_loss: 0.9948 - val_accuracy: 0.5482\n",
      "Epoch 46/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9532 - accuracy: 0.5709 - val_loss: 1.1777 - val_accuracy: 0.5015\n",
      "Epoch 47/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9512 - accuracy: 0.5727 - val_loss: 1.0553 - val_accuracy: 0.5352\n",
      "Epoch 48/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9583 - accuracy: 0.5685 - val_loss: 1.0261 - val_accuracy: 0.5439\n",
      "Epoch 49/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9635 - accuracy: 0.5673 - val_loss: 1.0448 - val_accuracy: 0.5396\n",
      "Epoch 50/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9441 - accuracy: 0.5758 - val_loss: 1.0218 - val_accuracy: 0.5447\n",
      "Epoch 51/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9490 - accuracy: 0.5716 - val_loss: 1.0210 - val_accuracy: 0.5421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9500 - accuracy: 0.5720 - val_loss: 1.0072 - val_accuracy: 0.5488\n",
      "Epoch 53/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9581 - accuracy: 0.5677 - val_loss: 1.0244 - val_accuracy: 0.5433\n",
      "Epoch 54/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9516 - accuracy: 0.5709 - val_loss: 1.0416 - val_accuracy: 0.5315\n",
      "Epoch 55/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9543 - accuracy: 0.5696 - val_loss: 1.1440 - val_accuracy: 0.4994\n",
      "Epoch 56/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9478 - accuracy: 0.5715 - val_loss: 0.9944 - val_accuracy: 0.5483\n",
      "Epoch 57/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9355 - accuracy: 0.5765 - val_loss: 1.0170 - val_accuracy: 0.5433\n",
      "Epoch 58/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9426 - accuracy: 0.5752 - val_loss: 1.1279 - val_accuracy: 0.5117\n",
      "Epoch 59/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9448 - accuracy: 0.5745 - val_loss: 1.0249 - val_accuracy: 0.5371\n",
      "Epoch 60/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9452 - accuracy: 0.5731 - val_loss: 1.1946 - val_accuracy: 0.4939\n",
      "Epoch 61/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9352 - accuracy: 0.5794 - val_loss: 1.0267 - val_accuracy: 0.5407\n",
      "Epoch 62/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9447 - accuracy: 0.5747 - val_loss: 1.0097 - val_accuracy: 0.5473\n",
      "Epoch 63/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9411 - accuracy: 0.5752 - val_loss: 1.0237 - val_accuracy: 0.5473\n",
      "Epoch 64/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9426 - accuracy: 0.5754 - val_loss: 1.0354 - val_accuracy: 0.5368\n",
      "Epoch 65/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9393 - accuracy: 0.5758 - val_loss: 1.1967 - val_accuracy: 0.4995\n",
      "Epoch 66/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9421 - accuracy: 0.5724 - val_loss: 1.0539 - val_accuracy: 0.5368\n",
      "Epoch 67/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9416 - accuracy: 0.5754 - val_loss: 1.0050 - val_accuracy: 0.5482\n",
      "Epoch 68/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9382 - accuracy: 0.5759 - val_loss: 1.0051 - val_accuracy: 0.5474\n",
      "Epoch 69/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9308 - accuracy: 0.5787 - val_loss: 1.0109 - val_accuracy: 0.5515\n",
      "Epoch 70/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9264 - accuracy: 0.5803 - val_loss: 1.0280 - val_accuracy: 0.5430\n",
      "Epoch 71/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9417 - accuracy: 0.5736 - val_loss: 1.0433 - val_accuracy: 0.5346\n",
      "Epoch 72/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9377 - accuracy: 0.5784 - val_loss: 1.0586 - val_accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9346 - accuracy: 0.5758 - val_loss: 1.0044 - val_accuracy: 0.5517\n",
      "Epoch 74/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9341 - accuracy: 0.5769 - val_loss: 1.0883 - val_accuracy: 0.5236\n",
      "Epoch 75/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9297 - accuracy: 0.5798 - val_loss: 0.9995 - val_accuracy: 0.5489\n",
      "Epoch 76/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9386 - accuracy: 0.5773 - val_loss: 1.0318 - val_accuracy: 0.5390\n",
      "Epoch 77/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9417 - accuracy: 0.5756 - val_loss: 1.0785 - val_accuracy: 0.5126\n",
      "Epoch 78/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9255 - accuracy: 0.5816 - val_loss: 1.0166 - val_accuracy: 0.5454\n",
      "Epoch 79/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9296 - accuracy: 0.5800 - val_loss: 1.0102 - val_accuracy: 0.5507\n",
      "Epoch 80/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9297 - accuracy: 0.5807 - val_loss: 1.0335 - val_accuracy: 0.5465\n",
      "Epoch 81/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9253 - accuracy: 0.5818 - val_loss: 1.0758 - val_accuracy: 0.5295\n",
      "Epoch 82/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9323 - accuracy: 0.5782 - val_loss: 1.0224 - val_accuracy: 0.5467\n",
      "Epoch 83/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9240 - accuracy: 0.5828 - val_loss: 1.0721 - val_accuracy: 0.5288\n",
      "Epoch 84/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9231 - accuracy: 0.5817 - val_loss: 0.9974 - val_accuracy: 0.5492\n",
      "Epoch 85/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9304 - accuracy: 0.5787 - val_loss: 1.0049 - val_accuracy: 0.5481\n",
      "Epoch 86/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9210 - accuracy: 0.5817 - val_loss: 1.0671 - val_accuracy: 0.5401\n",
      "Epoch 87/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9299 - accuracy: 0.5785 - val_loss: 1.0279 - val_accuracy: 0.5364\n",
      "Epoch 88/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9258 - accuracy: 0.5799 - val_loss: 1.0447 - val_accuracy: 0.5378\n",
      "Epoch 89/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9268 - accuracy: 0.5811 - val_loss: 1.2426 - val_accuracy: 0.4818\n",
      "Epoch 90/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9165 - accuracy: 0.5849 - val_loss: 1.0177 - val_accuracy: 0.5477\n",
      "Epoch 91/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9265 - accuracy: 0.5800 - val_loss: 1.0288 - val_accuracy: 0.5478\n",
      "Epoch 92/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9231 - accuracy: 0.5815 - val_loss: 1.0465 - val_accuracy: 0.5394\n",
      "Epoch 93/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9218 - accuracy: 0.5821 - val_loss: 1.0026 - val_accuracy: 0.5544\n",
      "Epoch 94/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9202 - accuracy: 0.5825 - val_loss: 1.0169 - val_accuracy: 0.5498\n",
      "Epoch 95/100\n",
      "63750/63750 [==============================] - 4s 58us/step - loss: 0.9175 - accuracy: 0.5857 - val_loss: 1.0329 - val_accuracy: 0.5364\n",
      "Epoch 96/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9210 - accuracy: 0.5832 - val_loss: 1.0545 - val_accuracy: 0.5388\n",
      "Epoch 97/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9323 - accuracy: 0.5783 - val_loss: 0.9973 - val_accuracy: 0.5537\n",
      "Epoch 98/100\n",
      "63750/63750 [==============================] - 4s 60us/step - loss: 0.9220 - accuracy: 0.5836 - val_loss: 1.1343 - val_accuracy: 0.4929\n",
      "Epoch 99/100\n",
      "63750/63750 [==============================] - 4s 59us/step - loss: 0.9197 - accuracy: 0.5813 - val_loss: 1.0005 - val_accuracy: 0.5501\n",
      "Epoch 100/100\n",
      "63750/63750 [==============================] - 4s 61us/step - loss: 0.9160 - accuracy: 0.5849 - val_loss: 1.0253 - val_accuracy: 0.5464\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# C. albicans || metapsilosis || orthopsilosis || parapsilosis || unidentified\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from PIL import Image\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "# First import the data by loading the file and extracting the correct section\n",
    "data_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4+b5+b6+b9_seqs.csv.npz', allow_pickle=True)\n",
    "labels_npz = np.load('../../analysis/arrays_test/20180108_FAH18647_b3+b4+b5+b6+b9_ids.csv.npz', allow_pickle=True)\n",
    "\n",
    "data = data_npz['arr_0']\n",
    "all_labels_onehot = labels_npz['arr_0']\n",
    "\n",
    "samples_per_class = 15000\n",
    "\n",
    "num_class = 5\n",
    "\n",
    "# Print the shape of the resulting dataframes to visually verify\n",
    "print('all_labels_onehot.shape: ', all_labels_onehot.shape)\n",
    "print('data.shape:', data.shape)\n",
    "\n",
    "# Separate the data into separate classes based on the labels\n",
    "data_class_3 = data[:samples_per_class,:]\n",
    "data_class_4 = data[samples_per_class:2*samples_per_class,:]\n",
    "data_class_5 = data[2*samples_per_class:3*samples_per_class,:]\n",
    "data_class_6 = data[3*samples_per_class:4*samples_per_class,:]\n",
    "data_class_9 = data[4*samples_per_class:,:]\n",
    "\n",
    "# Print an entry to visualise this\n",
    "print(data_class_3[50])\n",
    "print(data_class_4[50])\n",
    "print(data_class_5[50])\n",
    "print(data_class_6[50])\n",
    "print(data_class_9[50])\n",
    "\n",
    "# Print the shape of these new arrays to visually verify\n",
    "print('data_class_3.shape: ', data_class_3.shape)\n",
    "print('data_class_4.shape: ', data_class_4.shape)\n",
    "print('data_class_5.shape: ', data_class_5.shape)\n",
    "print('data_class_6.shape: ', data_class_6.shape)\n",
    "print('data_class_9.shape: ', data_class_9.shape)\n",
    "\n",
    "# Determine the total number of samples per class, and the total number of samples overall\n",
    "samples_count = samples_per_class*num_class\n",
    "print('samples_per_class: ', samples_per_class)\n",
    "print('samples_count: ', samples_count)\n",
    "\n",
    "# Create a vertically stacked arra containing all sequences, then join labels\n",
    "all_data = data_npz['arr_0']\n",
    "print('all_data.shape : ', all_data.shape)\n",
    "print('all_labels_onehot.shape : ', all_labels_onehot.shape)\n",
    "\n",
    "# Create a method for shuffling data\n",
    "shuffle_indices = random.sample(range(0, samples_count), samples_count)\n",
    "print(len(shuffle_indices))\n",
    "\n",
    "# Assign a percentage of data for training and the rest for testing\n",
    "train_size = math.floor(0.85*data.shape[0])\n",
    "print(train_size)\n",
    "indices_train = shuffle_indices[0:train_size]\n",
    "indices_test = shuffle_indices[train_size+1:samples_count]\n",
    "\n",
    "# Define the data vs labels for each of the training and test sets\n",
    "X_train = data[indices_train,:]\n",
    "Y_train = all_labels_onehot[indices_train]\n",
    "\n",
    "X_test = data[indices_test,:]\n",
    "Y_test = all_labels_onehot[indices_test]\n",
    "\n",
    "print('X_train.shape : ', X_train.shape)\n",
    "print('X_test.shape : ', X_test.shape)\n",
    "print('Y_train.shape : ', Y_train.shape)\n",
    "print('Y_test.shape : ', Y_test.shape)\n",
    "\n",
    "# Define the input dimension from X_train.shape[1]\n",
    "in_dim = X_train.shape[1]\n",
    "\n",
    "# define the keras model\n",
    "#model = Sequential()\n",
    "#model.add(Dense(128, input_dim=480, activation='relu'))\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "#model.add(Dense(32, activation='relu'))\n",
    "#model.add(Dense(2, activation='softmax'))\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=in_dim))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(num_class, activation='softmax'))\n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Run the model\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), batch_size=100, epochs=100, verbose=1)\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy for Candida species')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
